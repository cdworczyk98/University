{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.backend import clear_session\n",
    "from gensim import models\n",
    "\n",
    " \n",
    "from numpy import zeros, asarray, array\n",
    "from keras import layers\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, Input, Conv1D, concatenate\n",
    "from keras.layers import GlobalMaxPooling1D, MaxPooling1D \n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading plots to used later in graphing the model performance\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>note : some may consider portions of the follo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>note : some may consider portions of the follo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>every once in a while you see a film that is s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when i was growing up in 1970s , boys in my sc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the muppet movie is the first , and the best m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  note : some may consider portions of the follo...      1\n",
       "1  note : some may consider portions of the follo...      1\n",
       "2  every once in a while you see a film that is s...      1\n",
       "3  when i was growing up in 1970s , boys in my sc...      1\n",
       "4  the muppet movie is the first , and the best m...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = pd.read_csv('data/train.csv', header = None, delimiter=','), pd.read_csv('data/test.csv', header = None, delimiter=',')\n",
    "train_data.columns, test_data.columns = ['text','label'], ['text','label']\n",
    "\n",
    "#train, test = train.replace({'lable': {1: 'True', 0: 'False'}}), test.replace({'lable': {1: 'True', 0: 'False'}})\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'note : some may consider portions of the following text to be spoilers .  be forewarned .  among my fanatical ticker tape-worshipping friends , there\\'s one who happens to share the same philosophy espoused by the central character in darren aronofsky\\'s darkly original pi : the entire stock market can be reduced to nothing but a series of patterns which , through analysis , will produce information to accurately forecast future behaviour .   ( an example of the mentality involved : if the stock price goes up like this , and then down like that , and then sharply up this way , it then will go * this * way . )  while i freely admit that i know less than nothing about the market ( knowledge check : prices up -- good ; prices down -- bad ; most of the time , at least ) and hence really couldn\\'t comment with any authority , it\\'s always nonetheless struck me as an incredibly naive oversimplification of an astonishingly complex system ( and besides , if it were that simple , no doubt somebody would\\'ve already figured it all out ) .  the difference in this case is that while my colleague ( an otherwise assuredly realistic individual ) truly believes in this in and of itself as a valid forecaster , pi uses this ideology as a device with which to investigate its character\\'s psychosis .  it\\'s also vastly more convincing with its argument .   \" mathematics is the language of the universe , \" insists genius protagonist maximillian cohen ( sean gullette ) in a cool , mantra-like voice-over which repeats throughout the picture .  since nature can be expressed in numbers , and there are patterns everywhere in nature , he reasons with eminent logic that finding the patterns will allow him to predict anything -- the ups and downs of the stock market , how many games the yankees will win this year , the flavour of jam i\\'m going to put on my toast tomorrow morning .  obsessed with finding the proverbial key to the universe , max lives in paranoid , self-imposed solitude in a seedy nyc chinatown apartment , single-mindedly toiling away with his monstrous homemade computer system .  sullenly withdrawn and plauged by debilitating migraines , the elusive pursuit of a mysterious 216-digit number his machine spits out one day is driving him into madness .  the story , then , is basically an eccentricity , but it\\'s a clever , astute eccentricity , perceptively zeroing in on the modern mistrust of mathematical reductionism ; in an age where a dominant societal phobia is one\\'s individualism being replaced by a series of numeric identifiers , max\\'s all-consuming penchent for numbers at once creates a lingering , unsettling mood .  it helps matters that he\\'s not a particularly likable protagonist .  all attempts of friendliness from neighbours are curtly rebuffed by max , a spindly , neurotic-looking individual who hasn\\'t the time to indulge in pleasantries .  for a film which puts its lead character front and center ( mr . gullette appears in virtually every scene ) , pi takes a refreshing and effective approach in avoiding conventional aesthetics ; because of our ambivalence with max , we\\'re not so much avidly rooting for him to triumph with a moment of epiphany as we\\'re following him through this plot with a sense of mixed dread and morbid fascination -- it\\'s more disturbing journey than quest .  still , we do care about max\\'s fate .  teetering on the edge of dementia , he winds up being pursued by two different groups which want to pick his brain , both fronted by deliciously perky , resolutely cheerful representatives with inevitably duplictious intentions .  as we know , in films where paranoia is a dominant element ( see the truman show\\'s laura linney character ) , or for that matter , in real life , it\\'s always the ones who never stop smiling at you and are overly friendly that are the ones of which to be wary .  pi , a film that addresses patterns , itself intentionally adheres to an identifiable pattern cycle -- headache scene ; important revelation or bit of plot development ; pill-popping montage ; hallucinatory nightmare ( with decidedly cronenberg-esque undertones -- few other directors are as equally adept in bridging unsettling concepts and body-themed horror ) ; nosebleeding reality .  the repetitiveness , far from being tedious , is effectively maddening ; more than anything , the picture aims to get under our skins and take in events from max\\'s claustrophobic perspective .  in this regard , it wildly succeeds due to mr . aronofsky\\'s striking direction .  it\\'s a rarity that a film so completely immerses itself into a protagonist\\'s warped perspective of his surrounding , and high contrast black-and-white cinematography combined with constant usage of extreme close-ups lend a heightened sense of paranoia to the proceedings .   ( in some scenes , the stark composition in conjunction with the lumbering approach by mr . gullette make his character curiously resemble a latter-day max schreck , from nosferatu . )  using savage , jittery lensing and rapid cuts to create a sense of disorientation , the picture is often dizzying to behold , and max\\'s effective isolationism is emphasized by shots from the so-called snorri cam , which keep him in plain focus while the environment races by in blurred bursts .  pi\\'s raw , aggressive visuals are reminiscent of david lynch\\'s early work ( in particular , eraserhead ) .  the film\\'s sinister tone splashes onto the screen immediately with a dazzling opening credit sequence ably backed by a sly electronic score by clint mansell , and gradually increases in intensity .  still , amidst all its kafkaesque qualities and overall dispassionate mood , pi does occasionally display a sense of humour .  at one point , marcy dawson ( pamela hart , great fun ) entices max with the offer of an invaluable treasure : a one-of-a-kind . . .  computer chip .   \" isn\\'t it beautiful , \" she coos .  a showcase for mr . aronofsky\\'s technical virtuosity ( made for $60 000 , it\\'s since gone on to capture acclaim at the 1998 sundance film festival ) , pi is an intriguingly cerebral story which , ironically , is perhaps the most purely visceral film of the year .  '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"text\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    # Remove punctuations and numbers\n",
    "    sen = re.sub('[^a-zA-Z]', ' ', sen)\n",
    "\n",
    "    # Single character removal\n",
    "    sen = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sen)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sen = re.sub(r'\\s+', ' ', sen)\n",
    "\n",
    "    return sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train = []\n",
    "sentences_test = []\n",
    "\n",
    "train_sentences = list(train_data['text'])\n",
    "test_sentences = list(test_data['text'])\n",
    "\n",
    "for sen in train_sentences:\n",
    "    sentences_train.append(preprocess_text(sen))\n",
    "    \n",
    "for sen in test_sentences:\n",
    "    sentences_test.append(preprocess_text(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'note some may consider portions of the following text to be spoilers be forewarned among my fanatical ticker tape worshipping friends there one who happens to share the same philosophy espoused by the central character in darren aronofsky darkly original pi the entire stock market can be reduced to nothing but series of patterns which through analysis will produce information to accurately forecast future behaviour an example of the mentality involved if the stock price goes up like this and then down like that and then sharply up this way it then will go this way while freely admit that know less than nothing about the market knowledge check prices up good prices down bad most of the time at least and hence really couldn comment with any authority it always nonetheless struck me as an incredibly naive oversimplification of an astonishingly complex system and besides if it were that simple no doubt somebody would ve already figured it all out the difference in this case is that while my colleague an otherwise assuredly realistic individual truly believes in this in and of itself as valid forecaster pi uses this ideology as device with which to investigate its character psychosis it also vastly more convincing with its argument mathematics is the language of the universe insists genius protagonist maximillian cohen sean gullette in cool mantra like voice over which repeats throughout the picture since nature can be expressed in numbers and there are patterns everywhere in nature he reasons with eminent logic that finding the patterns will allow him to predict anything the ups and downs of the stock market how many games the yankees will win this year the flavour of jam m going to put on my toast tomorrow morning obsessed with finding the proverbial key to the universe max lives in paranoid self imposed solitude in seedy nyc chinatown apartment single mindedly toiling away with his monstrous homemade computer system sullenly withdrawn and plauged by debilitating migraines the elusive pursuit of mysterious digit number his machine spits out one day is driving him into madness the story then is basically an eccentricity but it a clever astute eccentricity perceptively zeroing in on the modern mistrust of mathematical reductionism in an age where dominant societal phobia is one individualism being replaced by series of numeric identifiers max all consuming penchent for numbers at once creates lingering unsettling mood it helps matters that he not particularly likable protagonist all attempts of friendliness from neighbours are curtly rebuffed by max spindly neurotic looking individual who hasn the time to indulge in pleasantries for film which puts its lead character front and center mr gullette appears in virtually every scene pi takes refreshing and effective approach in avoiding conventional aesthetics because of our ambivalence with max we re not so much avidly rooting for him to triumph with moment of epiphany as we re following him through this plot with sense of mixed dread and morbid fascination it more disturbing journey than quest still we do care about max fate teetering on the edge of dementia he winds up being pursued by two different groups which want to pick his brain both fronted by deliciously perky resolutely cheerful representatives with inevitably duplictious intentions as we know in films where paranoia is dominant element see the truman show laura linney character or for that matter in real life it always the ones who never stop smiling at you and are overly friendly that are the ones of which to be wary pi film that addresses patterns itself intentionally adheres to an identifiable pattern cycle headache scene important revelation or bit of plot development pill popping montage hallucinatory nightmare with decidedly cronenberg esque undertones few other directors are as equally adept in bridging unsettling concepts and body themed horror nosebleeding reality the repetitiveness far from being tedious is effectively maddening more than anything the picture aims to get under our skins and take in events from max claustrophobic perspective in this regard it wildly succeeds due to mr aronofsky striking direction it a rarity that film so completely immerses itself into protagonist warped perspective of his surrounding and high contrast black and white cinematography combined with constant usage of extreme close ups lend heightened sense of paranoia to the proceedings in some scenes the stark composition in conjunction with the lumbering approach by mr gullette make his character curiously resemble latter day max schreck from nosferatu using savage jittery lensing and rapid cuts to create sense of disorientation the picture is often dizzying to behold and max effective isolationism is emphasized by shots from the so called snorri cam which keep him in plain focus while the environment races by in blurred bursts pi raw aggressive visuals are reminiscent of david lynch early work in particular eraserhead the film sinister tone splashes onto the screen immediately with dazzling opening credit sequence ably backed by sly electronic score by clint mansell and gradually increases in intensity still amidst all its kafkaesque qualities and overall dispassionate mood pi does occasionally display sense of humour at one point marcy dawson pamela hart great fun entices max with the offer of an invaluable treasure one of kind computer chip isn it beautiful she coos showcase for mr aronofsky technical virtuosity made for it since gone on to capture acclaim at the sundance film festival pi is an intriguingly cerebral story which ironically is perhaps the most purely visceral film of the year '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['label'].values\n",
    "y_test = test_data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(sentences_train)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
    "X_test = tokenizer.texts_to_sequences(sentences_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 400\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    with open(filepath,'r', errors = 'ignore', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                word, *vector = line.split()\n",
    "                if word in word_index:\n",
    "                    idx = word_index[word] \n",
    "                    embedding_matrix[idx] = np.array(\n",
    "                        vector, dtype=np.float32)[:embedding_dim]\n",
    "            except:\n",
    "                print(word)\n",
    "                pass\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at\n",
      "to\n",
      "email\n",
      "or\n",
      "contact\n",
      "on\n",
      "by\n",
      "in\n",
      "at\n",
      "at\n",
      "is\n"
     ]
    }
   ],
   "source": [
    "                                 #embedding link: http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
    "    \n",
    "file_path='C:/Users/cdwor/Desktop/glove.840B.300d.txt'\n",
    "#file_path='C:/Users/cdwor/OneDrive/Education/University/Year 5/Data Wrangling/Coursework 2/data/glove.6B.100d.txt'\n",
    "embedding_dim = 300\n",
    "embedding_matrix = create_embedding_matrix(\n",
    "    file_path,\n",
    "    tokenizer.word_index, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33828, 300)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.27204001 -0.06203    -0.1884     ...  0.13015001 -0.18317001\n",
      "   0.1323    ]\n",
      " [-0.18567     0.066008   -0.25209001 ... -0.023452    0.12302\n",
      "   0.3312    ]\n",
      " ...\n",
      " [ 0.71087998  0.31716001  0.14848    ... -0.0027204   0.32440999\n",
      "  -0.31963   ]\n",
      " [-0.1211      0.29692999  0.40535    ...  0.18128    -0.2053\n",
      "  -0.60477   ]\n",
      " [-0.29899999  0.29299     0.45682001 ... -0.25531     0.55012\n",
      "  -0.0039112 ]]\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9369752867447085"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero_elements = np.count_nonzero(np.count_nonzero(embedding_matrix, axis=1))\n",
    "nonzero_elements / vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BF051F44C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BF00FB44C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BF7066D310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BF04200430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BF727B9E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BF00FCE430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BF00D54E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BF0002DC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BF000CA670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BF041824C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BF042001F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BF00D54DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BF00FE05E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BF70DC9700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BF727B9310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BF006B5CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BF00F624C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BF7066D1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BF70D775E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BF70E2DB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BF00D54DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Running source data set\n",
      "Best Accuracy : 0.5466\n",
      "{'vocab_size': 33828, 'num_filters': 32, 'maxlen': 400, 'kernel_size': 7, 'embedding_dim': 100}\n",
      "Test Accuracy : 0.6000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_model(num_filters, kernel_size, vocab_size, embedding_dim, maxlen):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(len(train_word_index)+1, EMBEDDING_DIM, weights=[train_embedding_weights], input_length=MAX_SEQUENCE_LENGTH, trainable=True))\n",
    "    model.add(layers.Conv1D(200, 5, activation='relu'))\n",
    "    model.add(layers.GlobalMaxPooling1D())\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Main settings\n",
    "embedding_dim = 100\n",
    "maxlen = 400\n",
    "output_file = 'data/output.txt'\n",
    "\n",
    "val_data = pd.read_csv('data/val.csv', header = None, delimiter=',')\n",
    "val_data.columns = ['text','label']\n",
    "\n",
    "X = []\n",
    "sentences = list(val_data['text'])\n",
    "for sen in sentences:\n",
    "    X.append(preprocess_text(sen))\n",
    "\n",
    "y = val_data['label'].values\n",
    "\n",
    "# Train-test split\n",
    "val_sentences_train, val_sentences_test, val_y_train, val_y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=1000)\n",
    "\n",
    "# Tokenize words\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(sentences_train)\n",
    "X_train_val = tokenizer.texts_to_sequences(val_sentences_train)\n",
    "X_test_val = tokenizer.texts_to_sequences(val_sentences_test)\n",
    "\n",
    "# Adding 1 because of reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Pad sequences with zeros\n",
    "X_train_val = pad_sequences(X_train_val, padding='post', maxlen=maxlen)\n",
    "X_test_val = pad_sequences(X_test_val, padding='post', maxlen=maxlen)\n",
    "\n",
    "\n",
    "# Parameter grid for grid search\n",
    "param_grid = dict(num_filters=[32, 64, 128],\n",
    "                  kernel_size=[3, 5, 7],\n",
    "                  vocab_size=[vocab_size],\n",
    "                  embedding_dim=[embedding_dim],\n",
    "                  maxlen=[maxlen],\n",
    "                )\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model,\n",
    "                        epochs=20, batch_size=16,\n",
    "                        verbose=False)\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n",
    "                          cv=4, verbose=1, n_iter=5)\n",
    "\n",
    "grid_result = grid.fit(X_train_val, val_y_train)\n",
    "\n",
    "# Evaluate testing set\n",
    "test_accuracy = grid.score(X_test_val, val_y_test)\n",
    "\n",
    "with open(output_file, 'a') as f:\n",
    "    s = ('Running {} data set\\nBest Accuracy : '\n",
    "         '{:.4f}\\n{}\\nTest Accuracy : {:.4f}\\n\\n')\n",
    "    output_string = s.format(\n",
    "        \"source\",\n",
    "        grid_result.best_score_,\n",
    "        grid_result.best_params_,\n",
    "        test_accuracy)\n",
    "    print(output_string)\n",
    "    f.write(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 400, 300)          10148400  \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 395, 200)          360200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 10,510,621\n",
      "Trainable params: 10,510,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 300\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=maxlen, trainable=True))\n",
    "model.add(layers.Conv1D(200, 6, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', f1_m, precision_m, recall_m])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "88/88 [==============================] - 19s 204ms/step - loss: 0.6957 - accuracy: 0.5157 - f1_m: 0.5523 - precision_m: 0.4268 - recall_m: 0.8246 - val_loss: 0.6860 - val_accuracy: 0.5000 - val_f1_m: 0.5067 - val_precision_m: 0.5000 - val_recall_m: 0.5200\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 17s 199ms/step - loss: 0.6607 - accuracy: 0.5291 - f1_m: 0.6675 - precision_m: 0.5172 - recall_m: 0.9941 - val_loss: 0.6151 - val_accuracy: 0.5625 - val_f1_m: 0.5091 - val_precision_m: 0.5029 - val_recall_m: 0.5200\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 0.4311 - accuracy: 0.8564 - f1_m: 0.8632 - precision_m: 0.8187 - recall_m: 0.9600 - val_loss: 0.3606 - val_accuracy: 0.8350 - val_f1_m: 0.4451 - val_precision_m: 0.5200 - val_recall_m: 0.3950\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 0.0922 - accuracy: 0.9790 - f1_m: 0.9756 - precision_m: 0.9784 - recall_m: 0.9782 - val_loss: 0.4628 - val_accuracy: 0.8050 - val_f1_m: 0.4950 - val_precision_m: 0.5133 - val_recall_m: 0.4800\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 0.0100 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.8200 - val_f1_m: 0.4882 - val_precision_m: 0.5133 - val_recall_m: 0.4675\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 0.0041 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.3790 - val_accuracy: 0.8400 - val_f1_m: 0.4793 - val_precision_m: 0.5200 - val_recall_m: 0.4475\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 17s 192ms/step - loss: 0.0023 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.3862 - val_accuracy: 0.8425 - val_f1_m: 0.4807 - val_precision_m: 0.5200 - val_recall_m: 0.4500_m: 1.0000 - precision_m: 1.0000 - re\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 17s 191ms/step - loss: 0.0017 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.3943 - val_accuracy: 0.8450 - val_f1_m: 0.4834 - val_precision_m: 0.5200 - val_recall_m: 0.4550\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 17s 196ms/step - loss: 0.0014 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.8475 - val_f1_m: 0.4834 - val_precision_m: 0.5200 - val_recall_m: 0.4550\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 0.0011 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.3984 - val_accuracy: 0.8400 - val_f1_m: 0.4793 - val_precision_m: 0.5200 - val_recall_m: 0.4475\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 9.1217e-04 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4066 - val_accuracy: 0.8500 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 7.5040e-04 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4070 - val_accuracy: 0.8450 - val_f1_m: 0.4821 - val_precision_m: 0.5200 - val_recall_m: 0.4525\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 17s 192ms/step - loss: 6.2450e-04 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4145 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 17s 191ms/step - loss: 5.4411e-04 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.8500 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 17s 192ms/step - loss: 4.7146e-04 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4204 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 17s 191ms/step - loss: 4.1961e-04 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4206 - val_accuracy: 0.8500 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 17s 191ms/step - loss: 3.6436e-04 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4229 - val_accuracy: 0.8500 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 17s 192ms/step - loss: 3.2409e-04 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4268 - val_accuracy: 0.8500 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 2.9589e-04 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4308 - val_accuracy: 0.8500 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 17s 191ms/step - loss: 2.6883e-04 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4338 - val_accuracy: 0.8500 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 2.3655e-04 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4338 - val_accuracy: 0.8500 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 17s 195ms/step - loss: 2.1745e-04 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4404 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 17s 192ms/step - loss: 1.9005e-04 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.8500 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 17s 191ms/step - loss: 1.7868e-04 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4407 - val_accuracy: 0.8500 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 17s 191ms/step - loss: 1.5568e-04 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4476 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.4738e-04 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4475 - val_accuracy: 0.8500 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 17s 192ms/step - loss: 1.3179e-04 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4516 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 17s 192ms/step - loss: 1.2414e-04 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4550 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 17s 192ms/step - loss: 1.1186e-04 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4550 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 17s 192ms/step - loss: 1.0576e-04 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4582 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 9.5579e-05 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4604 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 9.2302e-05 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4629 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 17s 195ms/step - loss: 8.7952e-05 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 17s 192ms/step - loss: 7.8542e-05 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4672 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 17s 192ms/step - loss: 7.2959e-05 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4687 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 6.7774e-05 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4711 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 17s 192ms/step - loss: 6.2892e-05 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4720 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 5.7490e-05 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4747 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 5.6748e-05 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4776 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 5.1579e-05 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4796 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 17s 192ms/step - loss: 4.7072e-05 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4796 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 17s 192ms/step - loss: 4.4415e-05 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 17s 192ms/step - loss: 4.2253e-05 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4838 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 17s 192ms/step - loss: 3.9333e-05 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4857 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 17s 192ms/step - loss: 3.7309e-05 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4881 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 3.5095e-05 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4910 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 17s 196ms/step - loss: 3.2435e-05 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4915 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 3.1407e-05 - accuracy: 1.0000 - f1_m: 0.9997 - precision_m: 0.9997 - recall_m: 0.9997 - val_loss: 0.4938 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 2.8814e-05 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4963 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 2.7535e-05 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.4977 - val_accuracy: 0.8475 - val_f1_m: 0.4847 - val_precision_m: 0.5200 - val_recall_m: 0.4575\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsIAAAFACAYAAAC2ghqXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABpy0lEQVR4nO3deXhTVfrA8e9N0jZd0tImQCmUxbLvFAREBCulgCJUx20G0RnEDZTFZQTBXZQfguuoqDAwuA3jCII6IlRxo6gI4gIKlH0vXeiatE3u/f0RGindS5s0t+/nefq0ubnL+6bt6duTc89RNE3TEEIIIYQQookx+DoAIYQQQgghfEEKYSGEEEII0SRJISyEEEIIIZokKYSFEEIIIUSTJIWwEEIIIYRokqQQFkIIIYQQTZIUwg3siy++QFEUjhw5UqvjFEXhrbfeaqCovMcbeRw4cABFUfjmm29qdd1LL72UyZMnn/f1ly9fjslkOu/zCCH0Q9p+afvrU33FLMqTQvgMRVGq/Gjfvn2dzjtkyBCOHz9OTExMrY47fvw411xzTZ2uKRrm9Tty5AiKovDFF1+U2X799ddz9OjRer2WEMI7pO3XF2n7RW1JN9YZx48f93z9/fffM378eL7//ntiY2MBMBqNZfYvLi4mMDCw2vMGBgYSHR1d63jqcoz4gzdfv+DgYIKDg712vcaopr8PQjQ20vbri7T9orakR/iM6Ohoz0dUVBQAzZs392xr0aIFL774In/5y1+IiIhgwoQJAMyZM4du3boREhJCbGwsd9xxBzk5OZ7znvv2WOnjDRs2MGzYMEJCQujevTuffvppmXjOfXtHURReeeUVJk6ciMViITY2lgULFpQ5JjMzk2uvvZbQ0FBatmzJQw89xM0330xiYmKVuVeXQ+nbP5s2bSI+Pp6QkBAuvPBCtm7dWuY8GzdupHfv3pjNZnr37s3GjRurvO6ePXtQFIXU1NQy27/77jsUReH3338H4IUXXqBv376EhYURHR3NDTfcUOaPV0XOff0OHjzI6NGjCQ4Opm3btrz00kvljnnnnXcYNGgQERER2Gw2rrjiCnbv3u15vvQPY0JCQpmeooreHvvf//5H//79CQoKokWLFkyZMoWCggLP83/9619JTEzk9ddfp127doSHhzN+/HhOnTpVZV7VxQiQnp7O3/72N1q2bInZbKZLly7885//9Dy/d+9err32WqKioggJCaF379589NFHleZybm9I6c/wxx9/zNChQzGbzbz++utkZ2dz44030rZtW4KDg+nSpQuLFi3i3MUrV65cSf/+/TGbzVitVsaMGUN2djbLli2jWbNmFBYWltn/scceo0OHDuXOI0R9kLZf2n5/aPvPVVJSwqxZs2jdujWBgYF0796dd955p8w+S5YsoVu3bp62dtiwYZ6fx9zcXP72t78RHR1NUFAQsbGx3HPPPbWKQS+kEK6Fxx57jIsuuoht27Yxb948wP0f4euvv87OnTtZvnw5X3zxBdOmTav2XPfddx8PPvggP/30EwMGDOD666/n9OnT1V5/2LBhbN++nfvvv58HHnigTIPzt7/9jZ9++omPPvqIzz//nCNHjvDBBx9UG0tNclBVldmzZ/PCCy+wbds2IiMjue6663A6nQAcO3aMsWPH0r9/f7Zt28aiRYuYPn16ldft1KkTgwcP5l//+leZ7W+++SYDBw6ka9eunm0LFy7kl19+YfXq1Rw6dIgbbrih2rxKaZrGVVddRWZmJl988QVr165l7dq1bNu2rcx+RUVFPPTQQ2zbto0NGzZgNBq54oorKC4uBvDs//7773P8+HG2bNlS4fV+/vlnxo0b5/le/etf/+Kjjz7ijjvuKLPfli1b2LhxIx9//DHr1q1j+/bt3HfffVXmUl2Mdrud4cOH89NPP/H222+zc+dOXnrpJUJCQgA4ceIEQ4YMITs7m7Vr1/LLL7/wxBNPYDDUvim49957+fvf/85vv/1GcnIyRUVF9OrViw8++ICdO3fy0EMP8cgjj7B8+XLPMcuWLePGG28kOTmZbdu2sXHjRkaPHo3L5eKGG25AURTee+89z/6qqrJs2TImT56Moii1jlGI+iBtv7T94Nu2/1wPPvggb7zxBs8//zy//vorN954IzfeeCOfffYZAFu3buWOO+5g9uzZ7Nq1iy+++IKbbrrJc/zcuXPZtm0ba9asYc+ePaxcuZJu3brVKgbd0EQ5X3/9tQZo+/fv92wDtEmTJlV77KpVq7TAwEDN5XJpmqZpGzdu1ADt8OHDZR6///77nmOOHz+uAdq6devKXO/NN98s8/juu+8uc60uXbpos2bN0jRN03bv3q0BWkpKiuf54uJirU2bNtqIESNqkX35HJYtW6YB2tatWz37bN68WQO033//XdM0TZszZ47Wtm1braSkxLPPhx9+WC6Pc7366qtas2bNNIfD4YnZZrNp//jHPyo9Ztu2bRqgHTlyRNM0Tdu/f78GaF9//bVnn7Ovu2HDBg3Qdu3a5Xk+PT1dM5vN2i233FLpdTIzMzVA++abbzRN07TDhw9rgLZx48Yy+y1btkwzGo2exzfeeKN24YUXltnngw8+0BRF0Q4cOKBpmqbdfPPNms1m8+StaZr29NNPa9HR0ZXGU5MYlyxZogUFBXl+3s41d+5crWXLllp+fn6Fz5+bi6aVz7v0Z3jFihXVxjdt2jQtMTHR8zg2NlabOnVqpfvffffd2sUXX+x5vG7dOs1kMmnHjh2r9lpCnC9p+6Xt17TG2fYPHz7cE3NBQYEWGBiovfzyy2X2SU5O1hISEjRNc38vw8PDtZycnArPN27cOO3mm2+u8ppNhfQI18LAgQPLbVu1ahXDhg0jJiaGsLAwJkyYQHFxMSdOnKjyXH379vV8HR0djdFo5OTJkzU+BqB169aeY3bu3AnA4MGDPc8HBAQwYMCAKs9Z0xwURaFPnz5lrg2Uuf7AgQPLvE00dOjQaq99/fXXY7fbWbt2LeB+Wyk3N7fMf/1ffPEFo0aNIjY2FovF4jnvwYMHqz1/aWw2m43OnTt7tjVv3pwuXbqU2W/79u1cddVVdOjQAYvFQtu2bWt1nVI7duxg2LBhZbYNHz4cTdM83yeAbt26ERQU5Hl89vezMtXFuHXrVrp3706bNm0qPH7r1q0MGTKE0NDQWuVUkXN/H1RVZf78+fTt2xebzUZYWBiLFy/2xJaens7hw4dJSkqq9Jy33347mzZt8rxOb7zxBldccQWtWrU673iFqCtp+6Xtr4mGbPvPlpaWRnFxcYXX2rFjBwAjR47kggsuoEOHDtxwww28/vrrZGRkePadMmUK//3vf+nZsyfTp0/nk08+QVXVWuWrF1II18K5xcN3333Htddey7Bhw1i9ejXbtm1j8eLFAJ63VCpT0c0W1f0QnnuMoijljqnt28c1zcFgMJS5aaT0OqXX1zSt3LVrEktkZCRXXnklK1asAGDFihVcccUVWK1WAA4dOsTll19O+/bt+fe//80PP/zgaTire41LVRTbuQoLC0lKSkJRFP75z3/y/fffs2XLFhRFqfF1zlbZ9c7eXtH3U6tiHGxNY6wu16qer2iIRElJSYX7nvv7sGjRIp5++mnuvvtuNmzYwPbt25k8eXK516+q6/fo0YOhQ4eyZMkS0tPTWbt2LbfddltV6QjR4KTtl7a/phqi7a/ptc7ONywsjB9++IHVq1fTuXNnFi9eTMeOHT3ju0eNGsWhQ4eYM2cODoeDG2+8kcsuuwyXy1XrOPydFMLn4ZtvvsFms/Hkk08yaNAgOnfuXOs5I+tL9+7dAdi8ebNnm9PpLHdTw7nqK4cePXrw3XfflfklOntux6rcdNNNrFu3jl27dvHxxx9z8803e57bsmULdrud559/nosvvpguXbrU6j/n0thOnTrFnj17PNsyMjLK3Azx22+/cerUKebNm0dCQgLdunUjOzu7TONU2nhV11D06NGDL7/8ssy2L7/8EkVRPN+nuqhJjP3792fHjh2Vfg/79+/Ppk2byty8cbYWLVrgcrnKvMbnjqerzFdffcXo0aO55ZZb6NevHx07dizzmrdo0YI2bdqUuznoXLfffjsrVqzg9ddfJzo6mtGjR9fo+kJ4i7T9f5C2v+z1GqLtP1fHjh0JCgoqd62vvvqKHj16eB4bjUaGDRvG448/ztatW2nVqlWZG+qioqL485//zGuvvcbHH3/Ml19+WabnuqmQQvg8dOnShVOnTrF06VL27dvHihUreOWVV3wSS6dOnbjyyiuZOnWq54f59ttvJzc3t8r/iOsrhzvvvJNTp05x22238dtvv/HZZ58xZ86cGh07ZswYoqKiuOGGG7BYLFx++eVl8lIUhUWLFrF//34++OADHn/88VrFNmLECPr06cONN97I999/z/bt25kwYUKZt/LatWtHUFAQL730Env37uWzzz5j+vTpZV670rf7169fz4kTJ8jOzq7wevfffz/btm3jnnvu4ffff2fdunXcfffdTJgwwfOWW13UJMY///nPtGvXjnHjxpGSksL+/fv57LPPWLlyJeB+O0xVVcaPH8+mTZvYv38/H330EZ988gngfgvYYrEwa9Ys9uzZw7p162r8enfp0oUvvviCjRs3snv3bubOnct3331XZp9HHnmE1157jSeeeILffvuNHTt28I9//KPMW3alc4A+8cQT3HLLLXW6kU+IhiRt/x+k7f9DQ7X95woJCWHatGk89NBDvPfee+zZs4ennnqKNWvW8OCDDwKwZs0annvuObZu3cqhQ4f44IMPOHz4sKcgnzNnDqtWrWLXrl3s2bOHt99+m7CwsHqN01/IX5jzMHbsWObMmcODDz5Ir169+Pe//80zzzzjs3iWLVtGz549GTNmDJdeeimtW7dm5MiRmM3mSo+prxxat27Nhx9+yPfff0/fvn2ZPn06zz77bI2ONZlM/OUvf2H79u3ccMMNBAQEeJ7r3bs3L730Eq+99hrdu3dn4cKFPP/887WKTVEUPvjgAyIiIhg2bBhjx47l8ssvJz4+3rOPzWbjrbfeYsOGDfTo0YP77ruPhQsXlinCDAYDL7/8Mv/5z3+IjY2lX79+FV6vd+/erF27li+//JI+ffowceJErrjiCs/bjnVVkxhDQkL48ssv6dmzJzfccAPdunVj6tSp2O12AFq1asU333zj+aPTo0cP5syZ4+n9iIqK4t133+Xbb7+ld+/ePPHEE+WmaqrMQw89xPDhwxk/fjwXXXQR2dnZ5e5Anzx5MsuXL+e///0vffv2ZdiwYXzyySdl/jCZzWYmTpyI0+nklltuOa/XTIiGIG3/H6Tt/0NDtf0VmTdvHrfeeiszZsygR48evPXWW7z11luMGDECcA89+fDDDxk9ejSdO3fm73//O3PnzmXSpEmAu519+OGH6d+/PwMGDODnn3/mk08+ISIiot5jbewUrS4DU4RfcLlcdO3alXHjxrFo0SJfhyNEjV133XXY7XY+/PBDX4cihN+Rtl+ImpOV5XTkq6++Ij09nX79+pGXl8dzzz3HgQMH+Otf/+rr0ISokezsbL7++mtWr17Nhg0bfB2OEH5B2n4h6k4KYR1xuVw8+eSTpKWlERAQQM+ePdm4cSO9evXydWhC1Ei/fv3IzMzk73//O5deeqmvwxHCL0jbL0TdydAIIYQQQgjRJMnNckIIIYQQokmSQlgIIYQQQjRJUggLIYQQQogmyac3yx07dqzS52w2W5lJ9vVI7znqPT/Qf456zw/qnmNMTEwDRNO4VdVmg/5/XvSeH+g/R8nP/9V3my09wkIIIYQQokmSQlgIIYQQQjRJUggLIYQQQogmSRbUEEIIIYSogqZpOBwOVFVFURRfh1OpkydPUlRU5OswGlRVOWqahsFgwGw21/j7JIWwEELozPbt21m2bBmqqjJixAiSk5PLPL927Vq+/vprAFRV5ciRIyxdupSwsDAfRCtE4+dwOAgICMBkatxlk8lkwmg0+jqMBlVdjk6nE4fDQXBwcM3OV1+BCSGE8D1VVVm6dClz587FarUye/ZsBgwYQJs2bTz7jBs3jnHjxgHwww8/8PHHH0sRLEQVVFVt9EWwcDOZTLXqFZcxwkIIoSNpaWlER0fTsmVLTCYTQ4YMYcuWLZXuv2nTJi6++GIvRiiE/2nMwyFEebX5flVbCL/yyitMnjyZe++9t8LnNU3jn//8J3fffTf33Xcf+/btq3mkQggh6lVWVhZWq9Xz2Gq1kpWVVeG+RUVFbN++ncGDB3srPCFEHWRlZTFy5EhGjhxJ37596d+/v+dxcXFxlcf+9NNPPPTQQ9Veo/RdovOVmprKTTfdVC/n8oZq+/kvvfRSRo8ezcsvv1zh8z/++CMnTpzgxRdfZM+ePSxZsoSnnnqq3gMVQghRPU3Tym2rrHdk69atdOnSpdJhESkpKaSkpAAwf/58bDZbldc2mUzV7uPP9J4f6D/HuuZ38uRJnw6NaNGiBRs3bgTgmWeeITQ0lClTpniedzqdnvjOjbN///7079+/2mv873//q5dYjUYjiqI06OtV3bmDgoJq/H2uNsru3buTnp5e6fM//PADw4YNQ1EUOnfuTEFBAdnZ2URGRtYogMZA0yAlJYj0dO8OMA8LM5CfH+LVa3qT3vMD/eeo9/wAhg9XOGv4rN+zWq1kZmZ6HmdmZlbaHm/atImhQ4dWeq7ExEQSExM9j6tbzencFZ/27DGRmhrIzTcX1jT8Rk1W7fJ/dc2vqKio0dyEpqoqqqpy11130axZM3799Vd69erFuHHjePTRR7Hb7ZjNZp599lk6duxIamoqixcvZsWKFSxatIijR49y6NAhjh49yuTJk7nlllsA6NSpE3v27CE1NZVnn32WyMhIdu3aRe/evXnppZdQFIXPPvuMxx57jKioKHr16sXBgwdZsWJFmfhcLheapuF0OsnOzubee+/l0KFDmM1mFixYQPfu3dm8eTMPP/ww4P5HfdWqVRQUFHDnnXeSl5eHy+Xi6aefZtCgQeXyN5lMOJ3OKl+joqKict/nylaWO+9yPSsrq0zVXfo2XEUNb216F7z5X+nixQamT/fVf3rNfHRdb2nm6wC8oJmvA2hgzXwdQIN64gmVv/9dPz1gcXFxHD9+nPT0dKKiokhNTWXatGnl9issLGTnzp3cfffdDRbLunVm5s8PJynJQatWaoNdR4imat++faxcuRKj0UheXh5r1qwB4KuvvuL//u//eOONN8odk5aWxnvvvUdBQQGXXHIJN910EwEBAWX2+fXXX/n888+Jjo5m/PjxbNmyhd69e/PAAw+watUq2rZtW6ZHujKLFi2iZ8+e/POf/+Sbb75h+vTpbNiwgcWLF/PUU09x4YUXUlBQQFBQEG+99RbDhw9n+vTpuFwu7HZ7/bxI1Tjv6q82b8PVpnfBW/+V/vabib//vTkJCQ4WLDiNN8fDR0VFVTp2Tw/0nh/oP0e95wfQvn1Uva5b72tGo5FJkyYxb948VFUlISGB2NhY1q9fD0BSUhIA33//PX369MFsNjdYLGPGOJg/P5xPPzXz17/qo1dYiIcfDmfnzoDqd6yF7t1LePzx3FofN3bsWE9PdW5uLjNnzmTfvn0oikJJSUmFx4wYMYKgoCDP8IFTp06Va8/69u3r2dajRw8OHz5MSEgI7dq1o23btgAkJyfz1ltvVRnf999/7ynGhw4dSnZ2Nrm5uVx44YU89thjXHXVVYwZM4aYmBj69u3Lvffei9PpZNSoUfTs2bPWr0ddnHchbLVay/wRqeptuMbGbleYMiWS8HCV558/jc3m3R4Lmw2CgvTbS6L3/ED/Oeo9PwCLBfQ2/3x8fDzx8fFltpUWwKUuvfRSLr300gaNo9cPb/FL0Fvc+fEmKYSFaAAhIX8MXXvmmWe4+OKLWbJkCYcPH+aaa66p8JigoCDP10ajEZfLVW6fwMDAMvtUNxShMpV1lt51112MGDGCzz//nCuvvJKVK1cyePBg3n//fT777DOmT5/OHXfcwbXXXlun69bGeRfCAwYMYN26dVx88cXs2bOHkJAQvymEH300nN27A3j33UyvF8FCCNEU9Cz6kexv95OVFUlUVPk/ikL4m7r03HpDXl4erVq1AuA///lPvZ8/Li6OgwcPcvjwYWJjY1m7dm21xwwePJhVq1Yxc+ZMUlNTiYqKwmKxcODAAbp160a3bt3YunUraWlpmM1moqOjmTBhAoWFhfzyyy+NoxB+/vnn2blzJ3l5edxxxx1cd911nv8MkpKS6NevH9u2bWPatGkEBgbWaMxIY/Dxx2beeiuUKVPyGDZMZ91BQgjRCJQMGADAQPVbUlKu4rrrvDPmT4im6M4772TmzJm8+uqrDTI3eHBwME899RQTJkwgKiqKvn37VnvMPffcwz333ENiYiJms5nnn38egCVLlpCamorBYKBz584kJCSwZs0aFi9ejMlkIjQ0lBdeeKHec6iIolXUb+0lx44dq/S5hhwjfOSIkaSk5nTo4GT16gzOegfAq+TuXP+n9xz1nh/UPcfGOka4IVXVZkMFr6WqEt2zF++WXM2Kof9g2bLsBo6wYcnvg/+ra36FhYVlhiE0VjWZUeF8FBQUEBoaiqZpPPjgg3To0IHbbrutwa5XkZrkWNH3q7I2u8mtLOd0wl13NcPlgpdfzvZZESyEELpnMFDcP55LA1P56iszhYWyOpcQ/uztt99m5MiRJCQkkJeXx8SJE30d0nlrcgtnv/RSGFu2BPGPf2TTvn35AeJCCCHqT3F8PK0//5wgcti4MYgrrnD4OiQhRB3ddtttXu8BbmhNrkf4o4+CufjiIq66SsaqCSFEQys+s6JVYlgq69Y13FRtQghRF02uED561EiXLhXPrSeEEKJ+lfTrh2YwcEO7TaSkmCku9nVEQgjxhyZVCOfmKuTlGYiJkSERQgjhDZrFgrNLFy5SNpObayA1Naj6g4QQwkuaVCF87Jh79RUphIUQwnuK+/en1YEfCAtx8sknMjxCCNF4SCEshBCiQRX3748hP4+bBmzn00/NVLCQlRCiCtdccw1ffPFFmW1vvPEGs2fPrvKYn376CYCJEyeSk5NTbp9FixaxePHiKq+9bt06du/e7Xn8zDPP8NVXX9Ui+oqlpqZy0003nfd5zleTKoSPHpVCWAghvK34zMIa17T5hlOnjGzbJvNWClEb48ePZ82aNWW2rVmzhuTk5Bod/+abbxIREVGna59bCN9///0MGzasTudqjJpUIXzsmBGjUaNlS1lOWQghvMXVoQOuqCjiHd8SGKjJ8AghaumKK64gJSWFoiL3SriHDx/m5MmTDBw4kFmzZjFmzBgSEhJYsGBBhccPGjSIrKwsAF544QUuueQSrr/+evbu3evZ5+233+byyy8nMTGRW2+9FbvdzpYtW9iwYQNPPvkkI0eO5MCBA8yYMYOPPvoIgK+//pqkpCRGjBjBPffc44lv0KBBLFy4kFGjRjFixAjS0tKqzC87O5tJkyaRmJjI2LFj2blzJwCbN29m5MiRjBw5kqSkJPLz8zl58iRXX301I0eO5LLLLuO77747r9e2SRXCR48aadnShanJzZ4shBA+pCiUxMcT8vNWhg4tYt06M75b01QI/1O6pHHp8Ig1a9Ywbtw4FEXhgQce4JNPPiElJYXNmzd7isiK/Pzzz6xdu5b169ezZMkSz9AJgDFjxvC///2PlJQUOnbsyLvvvsuFF17IyJEjmTt3Lhs2bKB9+/ae/R0Oh2dJ588++wyn08mKFSvKxPzpp58yceLEaodfLFq0iJ49e5KSksKsWbOYPn06AIsXL+app55iw4YNrF69GrPZzKpVqxg+fDgbNmxgw4YN9OjRow6v6B+aVEl47JiR1q1lWIQQQnhbcf/+hKekkHzjcaZ93oGdO0306NFwS8EK0VDCH36YgCqKzboo6d6d3Mcfr3Kf5ORk1qxZw6hRo1izZg3PPvssAB9++CFvv/02LpeL9PR09uzZQ/fu3Ss8x3fffcfo0aMJDg4GYOTIkZ7ndu3axYIFC8jNzaWgoIDhw4dXGc/evXtp27YtcXFxAFx77bX861//4tZbbwXchTVA7969+eSTT6o81/fff88bb7wBwNChQ8nOziY3N5cLL7yQxx57jKuuuooxY8YQExND3759mTFjBk6nk1GjRtGzZ88qz12dJtUjfOyYUcYHCyGED5QurDHWloqiaKxbF+zjiITwL6NHj+abb77hl19+weFw0KtXLw4dOsRrr73GypUrSUlJITExEYej6tUbFaXipc5nzpzJk08+yWeffcbMmTM9wxwqo1Xztk5QkHuqRKPRiKuaO2QrOpeiKNx1110888wzOBwOrrzyStLS0rjooot4//33iY6OZvr06bz33ntVnrs6TaZHWFXh+HEjV1whhbAQQnhbSd++aEYjtj1b6NLlOn79tcn8+RE6U13PbUMJDQ3loosu4p577vHcJJeXl0dwcDDh4eGcOnWKzz77jEGDBlV6jsGDBzNz5kymTp2Ky+Viw4YNTJw4EYD8/HxatmxJSUkJq1evJjo6GoCwsDAKCgrKnatjx44cPnyY/fv306FDB95//30GDx5cp9wGDx7MqlWrmDlzJqmpqURFRWGxWDhw4ADdunWjW7dubN26lbS0NEJDQ2nevDkTJkygsLCQX375hWuvvbZO14UmVAhnZBgoLlakR1gIIXxACw2lpFs3ArduJSJCJT+/Sb0hKUS9SE5OZvLkybz66qsA9OjRg549e5KQkEDbtm0ZOHBglcf36tWLK6+8kqSkJNq0aVOmaL7//vsZO3Ysbdq0oWvXruTn5wPuGSvuv/9+li5dyuuvv+7Z32w28+yzz3L77bfjcrno06ePp6iurXvuuYd77rmHxMREzGYzzz//PABLliwhNTUVg8FA586dSUhI4KOPPuLll1/GZDIRGhrKCy+8UKdrllK06vq2G9CxY8cqfc5ms5GRkVFv19q+PYArrmjOsmWZJCVV3d3vLfWdY2Oj9/xA/znqPT+oe44xMTENEE3jVlWbDdW/lhEPPkjwf//L6EEnOZkRwCef+NfPlvw++L+65ldYWEhISEgDRFS/TCYTTqe+x97XJMeKvl+VtdlN5l9ymUNYCCF8q7h/fwwFBfTQfiEvr8n8+RFCNGJNpiWSVeWEEMK3ShfW6F3wHfn5Fd+wI4QQ3tRkCuGjR42YzSqRkTJ5pRBC+IKrbVtcNhvdTn9HXp4UwkII32syhXDpHMKVzBoihBCioSkKxf37E3fqexwOAyUlvg5IiJrx4e1Uog5q8/1qUoVwTIwsrSyEEL5U0r8/zbP3YuOUDI8QfsNgMOj+JjS9cDqdGAw1L2+bzPRpx44ZufTSxjFbhBBCNFWl44QH8y35+QOJjJT7NkTjZzabcTgcFBUVVbogRWMQFBRU7UIY/q6qHDVNw2AwYDaba3y+JlEIFxdDerpBllcWQggfK+7dG9Vo4iLXZnJzK5/4X4jGRFEUz7LEjZnep7+D+s+xSQyNOHHCiKbJYhpCCOFzwcHktupId3bKohpCCJ9rEq1Q6dRp0iMshBC+54poRjNOy8wRQgifaxJDI2QxDSFEU7J9+3aWLVuGqqqMGDGC5OTkcvvs2LGD5cuX43K5sFgsPPbYY94LMCKcZpxkp/QICyF8rEkUwrKYhhCiqVBVlaVLlzJ37lysViuzZ89mwIABtGnTxrNPQUEBS5YsYc6cOdhsNnJycrwbZGQ4zdglPcJCCJ9rEv+OHz1qpFkzlZAQmQdQCKFvaWlpREdH07JlS0wmE0OGDGHLli1l9vnmm28YNGgQNpsNgIiICK/GaIwKJ4IcmT5NCOFzTaZHWMYHCyGagqysLKxWq+ex1Wplz549ZfY5fvw4TqeTRx99FLvdzuWXX87w4cO9FqMhKpwwcsjP9dolhRCiQk2mEG7TRgphIYT+VbSi0rnznrpcLvbv389DDz1EcXExc+fOpVOnTsTExJTZLyUlhZSUFADmz5/v6UGujMlkqnYfAENMKwxoGAtdNdq/sahpfv5M7zlKfv6vvnNsMoXwoEHFvg5DCCEanNVqJTMz0/M4MzOTyMjIcvtYLBbMZjNms5lu3bpx8ODBcoVwYmIiiYmJnsfVzd1Z0/k9g00mIgH78XQyMhw1yKpxkDla/Z/k5//qmuO57Vsp3Y8Rzs9XyMkxyI1yQogmIS4ujuPHj5Oeno7T6SQ1NZUBZ1ZzKzVgwAB+//13XC4XRUVFpKWl0bp1a6/FqIWHA6B4+yY9IYQ4h+57hGUOYSFEU2I0Gpk0aRLz5s1DVVUSEhKIjY1l/fr1ACQlJdGmTRv69u3Lfffdh8Fg4LLLLqNt27Zei1H1FMIySFgI4Vu6L4RlDmEhRFMTHx9PfHx8mW1JSUllHo8bN45x48Z5MywP7cwsFaZ86REWQviW7odGyBzCQgjRuJT2CAcUSCEshPAt3RfCR48aMRg0WraUQlgIIRqD0kI4yC5DI4QQvqX7QvjYMSMtWqgEBPg6EiGEEACaxQKA2SE9wkII39J9IXz0qCymIYQQjYrJhCMgjJCSHFzSPAshfEj3hfCxY0YZHyyEEI1MUXAEzThNQYEssyyE8B1dF8KaBsePS4+wEEI0NsUh4TTjNHl5UggLIXxH14VwZqaBoiJFeoSFEKKRcYa5e4Tz83X9Z0gI0cjVaB7h7du3s2zZMlRVZcSIESQnJ5d5Pj8/n1dffZWTJ08SEBDAnXfe6dXJ2Ssji2kIIUTjpFrCaUY6h3KlR1gI4TvV/iuuqipLly7lwQcf5LnnnmPTpk0cOXKkzD6rV6+mffv2LFy4kLvuuovly5c3VLy1IotpCCFE46RGhBNBjvQICyF8qtoWKC0tjejoaFq2bInJZGLIkCFs2bKlzD5HjhyhV69eALRu3ZpTp05x+vTpBgm4NqRHWAghGielmYwRFkL4XrWFcFZWFlar1fPYarWSlZVVZp927drx3XffAe7C+dSpU+X28YWjR42YzRpRUaqvQxFCCHEWQ9SZHmFZU0MI4UPVjhHWNK3cNkUp+x98cnIyy5cv5/7776dt27Z06NABg6F8jZ2SkkJKSgoA8+fPx2azVR6YyVTl8zWRmWmkTRto3vz8ztNQ6iPHxkzv+YH+c9R7ftA0cmyMTLZwjKgUZxUARl+HI4RooqothK1WK5mZmZ7HmZmZREZGltknJCSEKVOmAO7C+a677qJFixblzpWYmEhiYqLncUZGRqXXtdlsVT5fE/v22WjZ0klGRmb1O/tAfeTYmOk9P9B/jnrPD+qeY0xMTANE03SYbO5lll2ZeUAzn8YihGi6qh0aERcXx/Hjx0lPT8fpdJKamsqAAQPK7FNQUIDT6QTgs88+o1u3boSEhDRMxLVw7JjMISyEEI1SM3chrGbJ2AghhO9U2yNsNBqZNGkS8+bNQ1VVEhISiI2NZf369QAkJSVx9OhR/vGPf2AwGGjTpg133HFHgwdenZISOHnSIDNGCCFEI6SGuwthJSfHx5EIIZqyGs0jHB8fT3x8fJltSUlJnq87d+7Miy++WL+RnaeTJ41omiymIYQQjZEWEQGAkiM9wkII39HtBI6lcwjL0AghhGh8SnuETTJthBDCh3RbCJfOISw9wkII0fh4CuECGRohhPAd3RbCGRnu1Jo3l0JYCCEaG+1MIRxUKIWwEMJ3dFsI2+3uuY5DQsrPgyyEEMLHTCbspjDMDimEhRC+o+tC2GDQCAz0dSRCCCEqYg8MJ7hYCmEhhO/ouhAODtZQZBl7IYRolIqCIwgtyaGCBUyFEMIrdF8ICyGEaJyKQyJoxmkKC6XHQgjhG1IICyGE8AlnaDgR5JCXJ4WwEMI3pBAWQgjhEy5LOM04TX6+bv8UCSEaOd22Pg6HFMJCCNGYqRHuoRHSIyyE8JUaLbHsj6RHWAjRVG3fvp1ly5ahqiojRowgOTm5zPM7duxgwYIFtGjRAoBBgwZxzTXXeD1OpZm7RzgvVwphIYRv6LoQjoxUfR2GEEJ4laqqLF26lLlz52K1Wpk9ezYDBgygTZs2Zfbr1q0bs2bN8lGUbkpUOEZUHBkFQIBPYxFCNE26HRphtyuYzdIjLIRoWtLS0oiOjqZly5aYTCaGDBnCli1bfB1WhUxW9+pyJadyfRyJEKKp0nUhLEMjhBBNTVZWFlar1fPYarWSlZVVbr/du3dz//3389RTT3H48GFvhugR0NwCgCszzyfXF0II3Q6NkJvlhBBNkVbB6hTKOSsLdejQgVdeeQWz2cy2bdt45plnePHFF8sdl5KSQkpKCgDz58/HZrNVeW2TyVTtPmdzdXIP1wgsLK7Vcb5S2/z8kd5zlPz8RG4uyr59cOIEysmTcPIkyokTkJ6O0r07tgcfrLdL6bYQlqERQoimyGq1kpmZ6XmcmZlJZGRkmX1CQkI8X8fHx7N06VJyc3MJDw8vs19iYiKJiYmexxkZGVVe22azVbvP2QKMEAw4TqTX6jhfqW1+/kjvOUp+jYjLhfHYMYz792Pau5eAtDRMZz6MJ06U2121WFCbN4c65hgTE1Phdl0XwtIjLIRoauLi4jh+/Djp6elERUWRmprKtGnTyuxz+vRpIiIiUBSFtLQ0VFXFYrF4PVb1TOGt5MgYYSF0wenEtG8fpv37Uex2KCpCcThQiopQioownDqF6cABjAcOYDp8GKW42HOoarHg7NiRoksuwdmxI84LLsDVogVqixaozZujBQcD7mKfeiz2dVkIl5SA0ymFsBCi6TEajUyaNIl58+ahqioJCQnExsayfv16AJKSkvj2229Zv349RqORwMBAZsyYUW74hDdoEREAmPJzvH5tIcR50DR3UZuWRsBvv2HauZOAnTsJ2L0bxeGo9DA1JARX+/Y4u3TBMXo0rnbtcLZvjzMuDrVlS/BBO6TLQthud7+QflcIaxoBv/5KSdeuEFC3qYQMGRkY9+/H2bmz549MZRS7HdOOHRgKC+t0reoo4eEE5Zbv6XG1aIGzUycwGis/WNMwHj2Kcd8+Kvq1cMXE4LzgAjBUcb+npmE8dAhDdrb7NTWba5+EEH4oPj6e+Pj4MtuSkpI8X48ePZrRo0d7O6xy1DO90KZ86REWotFRVXdNceQIxqNHMR086Bm6YNq7F8NZf99dVivO7t0puPlmSrp1w9mpE1pYGFpQUJkPgoJ8UuxWRQrhhlZ640p13/jiYprdey8hq1bhatWKgr/9jYK//AXtnLF95x4TsHMngdu2EbBtG4HbtmE6eNDzdEmnTpTEx1McH09xv35owcEE/vijZ/+AnTtRnM56SLJy1kq2q2FhlPTt644tPp6S7t0xHTpUJhdjenqV51YjIiju29eTY0nXrpj27SPwzPEB27ZhPDNWUgsIoKRnT/d+Z/Z3nVlM4Lw4HO4PvdJ7fgAN/DsgqhAQQKEhlEC79AgL4VWahuH4cXeH08mTGE+exHDyJMYTJ9wfR49iPHaszNAFAFd0NM6OHbFffTXOuDiccXGUdO2K2qJFoytwa0oK4XqmFBYS8PPPZQo6gJxHH8Vx5ZUV/qAoOTlETZ5MUGoq+bfcQsDvvxP+1FOEPfss9muvpWDyZJxxcRiOHfMUeYHbthHwyy8oRUWA+4ezOD6egptuwnnBBQT89huB27YRtGEDIStXlrmeGhpKSb9+5E+Z4i6Qqyq2z0NERAQ5Oef8gTvTS1v6+oS9/DKKy1VmF2eHDhRdcgnF8fE4u3QBk6n8Ofbv97wOQS+8gKKWXTylpGNHikaMoDg+HjUqioCffiJw2zZC3nkHw9Kl9ZpnxcPv9UPv+TkfewwmT/Z1GE1WYUAEZimEhTg/qorh5EmU/fsJzMhwd8KpqvuzpmE4fdrdk7tnj6dX99x3g7WAAFwtW6K2bElJ797YL78cV+vWf3y0bYsWFuajBBuOFMLnQ9MwntMDGfDbb57Cztm+PUUXX4xp716i7rwT+9q15Dz1lPs/pzOMR48SNXEipn37yH7xRex/+hMApp07CV26lJD//IfQN9/EZbNhPDM4XDObKe7Vi4Kbb6a4f393sXfO3ZBFpW+DlhaeW7eiFBVR3K9f9cMS6uvlsdkormhA+8CB2M8s56rY7QT8/DOmnTtxtW1LSb9+qFFR1Z984EDs11/vPkdBAQE//UTA77/jvOACivv2RWvWrMzujiuucH/hdGL6/XcCf/wRw7lFeh2EhIZSWFBw3udprPSeH0Dw8OG+DqFJswdFEFwshbAQ1dI0DCdOELBjBwE7d7pvOjtyxP1x7BhKSQkAVU2e5oyJwdmpE4V//jPOuDhcsbG4oqNRo6NRmzWrerihTkkhXAtKbi6B27cTsHWrp/g1nD4N/PFWf/5dd3nefvcUdE4nYa+/jmXhQoISEsh59FHs11yDsn07tnHjUOx2Mt9+m+KLL/Zcy9m9OzmLFpE3ezYhb72Faf9+zzCAkm7dIDCwhkEruNq1w96uXb2+FvVFCw6meNAgigcNqvs5QkMpHjKE4iFDqt/ZZMLZsyfOnj3rfL2zmW028v1lqpo60Ht+4M6xPu9AFrXjMIcTUihjhIU4m2K3u3tvd+0i4PffCdixA9OOHRjPWhzHFR2Nq3Vrivv1w3Xllbhatya0SxdyHQ40RXG/A33mQ7NYcMbFoYWG+jCrxkkK4SoodjvBq1b9Mf52zx4UTUNTFJydOmEfM4aSMz2yzo4dK+9lNZnInzIFe1ISkffeS+SMGYT85z+Yfv4ZV3g4mR984B4CUAHVZiN/xozzykMIIRqr4uAILM5MNM1vhxgKUXNFRZgOHcKQkYGSl4chL8/9OT//j+ELu3djPHQI5cw9RlpQECVduuAYNYqSHj1w9uhBSbduaBVMeRhis1Ek/9jXihTCVYj4+9/dN69FRlISH499/Hh3b2/fvmjnTDxfE66OHclYtYrQ5cuxPP00WufOZPzzn6jR0ecVpxBC+KuSsAgi2IvDAWemCRXCf7lcGDIzMaSnu29CO3rUPa/u3r2Y9u1zF7jn3NNSSgsIwNmhAyW9e1N47bU4O3fG2aULzvbty98rI+qNLl/Z+iiEA7ZuJWTVKvKmTiVv9uz666owGim45RYKr74aa7t2qBVMLyaEEE2FKyycZpzmaL6B4OCKCwQhGp2z7r8J3LqVgJ9+wnjsmLun95wbwFWzGdcFF1DSqxf25GT3QhHR0WgWC2pYmOczZrO8LeIDui2EB/Id/ebOwfHma57VSGpMVYl45BFcLVqQP316g/xgapGRNR/nK4QQOqVFRNCM0/yeC82bl39esdtRsrJQW7f2fnCiaSouxnTwIMYjR9zDFgoKUAoKUPLzUQoKMKWluaf4PDMEQQ0NpaR3bxwJCagtWrhnXjjz2RUdjdqqVZO8Cc1f6LYQvoSvidz8Gdn/+59nJoaaCv7gAwJ//JHsZ5+VgeVCCNGAtGYWTLiwZ9ghLqjc82EvvkjosmWc3LpV2mNRfzQNw8mTmA4cwLR/P6a9ezHu3UtAWhrGgwfL9ep6DgsKwtW6NUUJCZ5Zm5xdu3plJibRMHRbCIfgnh8vZOXKWhXCSmEh4fPmUdy7N/Zrr22oEIUQQgCGSPcKmEUn84DyhXDAr79iyMvDvGED9uRk7wYn/N+ZVUoDfv6ZgF9+wXTwIM1378Z44AAGu/2P3QIDcV5wASVdu2IfOxZnx44427ZFCw9HCwtDDQlxz6Fbx1VfReOl20LYhnvu06BNmzAeOoSrbdsaHRv26qsYT5wg+9VX5a0MIYRoYCab+8734vQ8KpoB1bR3LwDmNWukEBZ/cDjc8+n+8guG/HzPwhGlH0pBgfv5n3/GmJ0NgGY0QseOuNq2pWjoUJzt2+Pq0AFnu3a4YmOlV7eJ0mUh7HAoWJR8tIBAKCkh5L33yLv33mqPMxw9Sugrr2C/8kqKBw70QqRCCNG0mWzuGXhcmRXcOOxwYDx0CM1sxvzFFyg5OWgREV6OUDQGxkOHCPz+ewJ//JGAH38kYOdOzwISFdFMJpylU4716kVJ796UdOuGLTaWLJleTJxFl4Ww3a4QbixAtVop6dyZ4P/8h7yZM6vt4Q2fPx9F08idM8dLkQohRNMW1NJdCKtZ5VeXMx04gKJp5N94I2FLlmBet86zoqTQN0NGBoGbNhH0zTcEffMNpkOHAFBDQijp04f8W2+lpF8/ivv2RY2MLLN4BIri7t2Vd3VFDeiyEHY4FCzGQtSQEAqvv56oKVMI3LSJ4ksuqfQYz3Rp06a53yIRQgjR4IJahgGgnc4r95wpLQ0A+5/+hHn9eoI//FAKYT1wOjGvW0fI229jPHUKDAY0g8FduBoMKPn5BOzZA4AaHk7RRRdRcOutFA0e7F58SoYwiHqky0LYblcIMxSghYTgGDUKNSKCkJUrKy+Ez54u7a67vBusEEI0YQHN3UMdDDkV9AifKYSdcXHYx40j7NVXMWRl/bF8vfArSnY2oe++S8jy5ZiOHsUZG0tJ9+7uMb2qCqrqHuNrs2H/058oGjqUkl69ZDEJ0aB0+dNltyuEKQXu+YPNZuxXXUXIv/9NTiXjy8Jeftk9Xdpzz8n0PEII4UXqmWVijXnlxwib9u7FGRODFhqK/corsfzjH5g//pjCiRO9HaY4h3H/fgw5OagREWgREajh4X8UrJqGkp+PISMDQ0YGxowMgr78kuD//heD3U7RRReR+/jjOEaOlN5d4XO6LYRDKUALcb/lVnj99YQuX07wmjUU3nRTmX0DU1OxLFhA4fjxMl2aEEJ4W2AghUoIpoIKeoT37sUVFweAs0cPSuLiCF67VgphXykpwbxuHaH/+hdBmzeXe1oNC0MLCcGQk4NSVFTmOS0oiMKrrqLglltwdu/urYiFqJZuC+EQrRAtpAWA+47Rbt0IWbmyTCFsSE8ncsoUnB06kLNggSxtKIQQPpBnbEZgwTk9wpqGKS2Nwuuucz9WFBzjxxP23HMYTp5EbdnS+4E2UYbjxwl9+21C3nkH48mTOGNjyX3wQUo6d8aQk+MufHNzMZw+jVJYiNqsGarVimqzodpsuGw2XLGxMuOHaJR0WwgHawV/LK2sKBRefz0Rjz6K6fff3avAOJ1ETpmCkpdH9r//7Z4oWwghhNcVBEQQ5ChbCBtOnsRQUICzY0fPNvu4cViefZbgjz+mYNIkb4epL6qKcd8+91y7v/7q/ti9G4Oq0lJV3fuc6RwyZGWBqlKUkMDpBQsoSkiQIQ1CN/RbCKuFfxTCgP3qqwl/8klCVq4k95FHsCxcSNDmzWQ/95y7MBZCCOET9sAIgotOl9l29o1ypZydOlHSrRvBa9ZIIVxbDgeB27YRtHkzgZs3E/DTTxgK3SuwagEBlHTpQtHQoQRFRuJwONw3rZ2hWq0UXncdrvbtfRS8EA1Ht4Ww2VWAMyTEs021WnEkJRH8/vsUDx6M5aWXKPjzn7GXvu0mhBDCJ4rM4YRkZ5bZVlEhDO5e4fD/+z+MR4/iat3aazH6HbudwO3bCfz2W4I2bSJw2zaUoiI0g4GSXr0ovOEGSnr2pKRHD5ydO0NgIAA2m40cWXBCNCE1KoS3b9/OsmXLUFWVESNGkHzOMpeFhYW8+OKLZGZm4nK5uPLKK0lISGiIeGvEXghmVyF5ZxXCAIXXXUfw//5H5G23UdK9OzlPPOGjCIUQQpQqCo6g5al9ZbaZ9u1DDQlBbdWqzPbSQtj84YcU3HGHN8Ns1JSCAgJ/+IHAb791f2zfjlJcjKYolPTsScFf/0rRRRdRPHCgjNUV4izVFsKqqrJ06VLmzp2L1Wpl9uzZDBgwgDZt2nj2WbduHW3atGHWrFnk5uYyffp0LrnkEky+mvvP7gBAO6cQLkpIwNWiBUphIVmvvQZnDZ0QQgjhGyVh4VjU05y9YK4pLc09Pvicm5hd7dtT3KcPwWvX6rsQVlWMx45BcbF7jl2XC1wuFJcLw6lTmPbt83wY9+3DeOwYiqahGY2U9O5NwS23UDRokBS+QlSj2ko1LS2N6OhoWp65Q3fIkCFs2bKlTCGsKAoOhwNN03A4HISFhWHw0dKGmgYG+5lxT+cWuiYTWStWoBmNuC64wAfRCSGEOJcrLIJmnOaIQyPI7C58TWlpFA8cWOH+9nHjiHjiCYz79+Pq0MGboTYsTSNg2zaCP/yQ4I8+wnj8eJW7q+HhOOPiKB40COcFF1ASH0/xgAEyH74QtVBtIZyVlYXVavU8tlqt7Dmz9GGp0aNHs2DBAm6//XbsdjszZ870WSFcVATB2AH3muTnKunVy9shCSGEqIIaEU4ATgozighqY0ax2zEdPUrhOeODS9mvvJKIJ54geM0a8mfM8G6w50PTUPLyUBwOlKIi92eHAyUnB/Pnn2P+6CNMR4+iBQbiuPRSiu6+2z2jkdHoXoLYaASjETUqCucFF6BarTLtpxDnqdpCWDvrztFSyjm/eD/99BPt2rXj4Ycf5uTJkzzxxBN07dqVkHMK0ZSUFFJSUgCYP38+Nput8sBMpiqfr0xWFoTivsnC0rIloXU4h7fUNUd/off8QP856j0/aBo5NnoR4QA4TuRCGzPGvXsBykyddja1dWuKLrqIkHffJf/uuxv/VF5FRYS89x5hr76K6cCBCnfRAgIoGj6cvL//HUdSElp4uHdjFKKJqrYQtlqtZGb+cTdvZmYmkZGRZfbZuHEjycnJKIpCdHQ0LVq04NixY3Q8pxFLTEwkMTHR8zijijtTbTZblc9X5vhxA6EUAJBTUkJRI777ta45+gu95wf6z1Hv+UHdc4yJiWmAaJomQ5R7DKvjRC7QAlM1hTBAwd/+RtRttxH02WcUJSV5I8xaU/LzCXnrLcJefx3jyZMU9+lDzty5aCEhaGYzmtkMZjNacDDFffrIWF4hfKDaQjguLo7jx4+Tnp5OVFQUqampTJs2rcw+NpuNX375hW7dunH69GmOHTtGixYtGizoqpQurwzlb5YTQoimoLqZfkqlpaUxZ84cZs6cyeDBg70b5FkMURYASjLyAAhIS0NTFJxVzFvrGDUKV6tWhC5b5tNC2HjwIMaTJ8HhQCku9nyYdu0idMUKDKdPU3TxxWQ//zzFl1wiQxmEaGSqLYSNRiOTJk1i3rx5qKpKQkICsbGxrF+/HoCkpCT+9Kc/8corr3DvvfcCMGHCBMJ99LaO3a4Qwpmb5aQQFkI0MTWZ6ad0v7fffpu+ffv6JtCzBDR3/71wnnKvLmfcuxdXbGzVM/uYTBRMnEj4ggV/zDDhRabdu7EsXEjwxx9Xuo999Gjyp06lJD7ei5EJIWqjRvObxcfHE3/OL3LSWf+BR0VFMXfu3PqNrI6kR1gI0ZTVZKYfgE8++YRBgwax98wwBF8KbOHuEVaz/ugRrklhWzhhApbnnydk+XJyn3yyQWMsZTx4EMuiRQSvXo0WHEzejBkUDRoEQUFogYFogYEQFIQaEYHavLlXYhJC1J3uVpYrUwjLPMFCiCamJjP9ZGVl8f333/PII4/w6quvejvEcszR7h5hLTvHPX/u3r0UXXRRtcepNhv2sWMJ+c9/yHvgATSL5fyDcToxHjzons2hpASlpARKSlCKizFu3EiL5cvdvdG33Ub+1KmoUVHnf00hhM/ouxCWHmEhRBNTk5l+li9fzoQJE6qd5rI2M/1A3WfgCOnhLmCD7A5sDgcGhwNz374E1uBcysyZGFatovm6dah33lnra1NQgPL99yipqRg2bUL57juU/PwKd9UCAlAnT8b1wAMExsSgxxJY77OoSH7+r75z1GUhLGOEhRBNVU1m+tm7dy8vvPACALm5ufz4448YDAYGnrOARW1m+oG6z8ChaRBIMK7MDPK2bMEKnI6Oprgm57rgAmx9+6L84x9kXHNNzW5G0zSCvvqKsBdfJHDLFhSXy31zXteuFP/pTxT37YtmsaAFBEBAANqZj4i+fckICHCfQ6ezqeh9phjJz//V90w/uiuEHQ4ZGiGEaLpqMtPPyy+/XObr/v37lyuCvUlRIEdphqkgF1Oaex742tz8VvDXvxI5YwaB33zjnpmhCoHffotlwQKCvvsOZ0wM+VOmUDxoEMXx8dVPX2az6bYAFqKp0l0hXDo0Qg0yg49WtxNCCF+pyUw/jVG+sRkBhbmY9u5FDQ9HrcVbn/YrryT88ccJXb680kI4YOtWwp95hqCvv8bVsiWn582j8M9/hqCg+kpBCOGHdFkIN6NAeoOFEE1WdTP9nG3q1KneCKla+QERmO05mNJO4oyLq918u2YzhX/5C2GvvILxyBFcpTNkaBpBX39N6OLFmL/8EpfVSs7DD1Nw001VT80mhGgydNdlWjpGWAuV8cFCCOEv7IERmItyMO3dW6c5gQtvugmAkBUroLiY4P/+l+YjR2L9858J+O03cmfPJn3zZgpuv12KYCGEhy57hC2GArlRTggh/IjdHEGnzJ8w5p9w9wjXkqt1axyjRhH65puEvP8+xhMnKOncmexnn8WenCxDIIQQFdJlIRxuyJehEUII4UeKg8Np7jwB1O5GubMV3HYb5k8/paRXL04/8wxFCQmypLEQokq6LIRDlULpERZCCD9SEvLHjA11LYSLBw7kxK5d0v4LIWpMl2OEwxQZGiGEEP7EZTmzupzRiLNduzqfR9p+IURt6LIQDpVZI4QQwq+o4e5C2Nm2LQQG+jgaIURTobtC2OE4M2uEFMJCCOE3tGbuoRGOdnUbFiGEEHWhu0LYblcIVmWMsBBC+BNDpAWA/DadfByJEKIp0WUhbFZljLAQQvgTQ5R7aER2S+kRFkJ4j+4KYUehhlm1SyEshBB+pLhHLxZwPwf6jvV1KEKIJkR3hTCFdgAZIyyEEH4kpJmJB1hAphbl61CEEE2I7gphxe4uhFXpERZCCL9hsWgA5OfLAhhCCO/RXSFssBcC0iMshBD+xGJRAcjL092fJSFEI6arFkdVwVQsQyOEEMLfSI+wEMIXdFUIFxW5F9MAWV1ICCH8SUiIhsGgkZurqz9LQohGTlctjt3uXkwDpBAWQgh/oijuXmHpERZCeJPuCmHpERZCCP8UFqZKj7AQwqt01eKUKYRljLAQQvgV6REWQnib7gphGRohhBD+yWJRZdYIIYRX6arFkaERQgjhvywWjbw86REWQniPFMJCCCEahbAwTXqEhRBepasWp0whHBTk42iEEELUhsWiyhhhIYRX6aoQdjjcY4Rd5mAw6Co1IYTQPYtFIzdXCmEhhPfoqlos7RFWg2VYhBBC+JuwMBWHw0BJia8jEUI0FboshGV8sBBC+J/wcFlmWQjhXboshJE5hIUQwu+EhakAcsOcEMJrdNXaeOYRDpUeYSGE8DcWi7tHWKZQE0J4i8nXAdQnu13BYihAC5EeYSFE07V9+3aWLVuGqqqMGDGC5OTkMs9v2bKFlStXoigKRqORv/71r3Tt2tU3wZ7FYnH3COfn66qPRgjRiOmuEA5TCtBCIn0dihBC+ISqqixdupS5c+ditVqZPXs2AwYMoE2bNp59evXqxYABA1AUhYMHD/Lcc8/x/PPP+y7oM0p7hGXmCCGEt+jq325PISxjhIUQTVRaWhrR0dG0bNkSk8nEkCFD2LJlS5l9zGYziuIuNouKijxf+1rpGGHpERZCeIvueoRDKJRZI4QQTVZWVhZWq9Xz2Gq1smfPnnL7ff/997zzzjvk5OQwe/Zsb4ZYqdJZI2SMsBDCW/RXCGsyfZoQounSNK3ctop6fAcOHMjAgQPZuXMnK1eu5KGHHiq3T0pKCikpKQDMnz8fm81W5bVNJlO1+1SltOlW1TBstsbXjp9vfv5A7zlKfv6vvnPUXSEcrBZQLIWwEKKJslqtZGZmeh5nZmYSGVn5fRPdu3fn5ZdfJjc3l/Dw8DLPJSYmkpiY6HmckZFR5bVtNlu1+1RF08BobMWJE3YyMvLqfJ6Gcr75+QO95yj5+b+65hgTE1Phdl0NxCoqVAnSimSMsBCiyYqLi+P48eOkp6fjdDpJTU1lwIABZfY5ceKEp+d43759OJ1OLBaLL8ItQ1HcN8zJghpCCG/RVY+wVmB3f5YeYSFEE2U0Gpk0aRLz5s1DVVUSEhKIjY1l/fr1ACQlJfHtt9/y1VdfYTQaCQwMZObMmY3mhjmLRSU3V1d9NEKIRqxGhXB1c1KuXbuWr7/+GnBP3XPkyBGWLl1KWFhYvQdcFaWwEEB6hIUQTVp8fDzx8fFltiUlJXm+Tk5OLteONxZhYdIjLITwnmoL4ZrMSTlu3DjGjRsHwA8//MDHH3/s9SIYwOiQQlgIIfxZeLj0CAshvKfa1qYmc1KebdOmTVx88cX1GmRNGRwyNEIIIfyZ9AgLIbyp2kK4ojkps7KyKty3qKiI7du3M3jw4PqLsBZMRWd6hKUQFkIIv2SxqOTlSY+wEMI7qh0aUdM5KQG2bt1Kly5dKh0WUZs5KWs7T5zLBQElvwEQ3qoVmh/Mo6f3+f70nh/oP0e95wdNI0d/YrFosqCGEMJrqi2EazMn5aZNmxg6dGil56rNnJS1nSeuoEAhlAIAThcXU+IH8+jpfb4/vecH+s9R7/lB/c9JKc6PxaLKEstCCK+ptrWpyZyUAIWFhezcubPC57yhdHllkKERQgjhr8LCNIqKFIqKfB2JEKIpqLZHuCZzUoJ73fo+ffpgNpsbNuJK2O1/9AhLISyEEP4pPFwFID/fQFCQ6uNohBB6V6N5hKubkxLg0ksv5dJLL623wGrr7EJYlenThBDCL4WFue9LyctTOOs+bSGEaBC6GYhVpkdYCmEhhPBLFou7EJYp1IQQ3qCrQjiEQjRFAR8NzxBCCHF+LBb3cAhZVEMI4Q26aWlKe4Rd5hCoZHo3IYQQjZv0CAshvEmfhbAQQgi/FBbm7hGWRTWEEN6gm5amtBDWzDI+WAgh/FV4+B83ywkhREPTVSEcQqFMnSaEEH5MeoSFEN6km5bG0yMcKoWwEEL4q6AgCAjQZIywEMIrdFcIK6EyNEIIIfyVorhnjpBZI4QQ3qCblsazxLIUwkII4dcsFukRFkJ4h24KYYdDIUwpABkjLIQQfi0sTJMxwkIIr9BNS2O3uwthVQphIYTwa+HhqswaIYTwCl0VwqFagcwaIYQQfk56hIUQ3qKblsZuVwimEC1YxggLIYQ/s1hUGSMshPAK3RTCRQUuArViKYSFEMLPWSwaublSCAshGp5uCmEKCgFkaIQQQvg5d4+wAU3zdSRCCL3TTSGs2M8UwtIjLIQQfi0sTKOkRMHh8HUkQgi9008hXGgHpEdYCCH8ncXiXmY5P183f6KEEI2UbloZg12GRgghhB5YLO4xETKFmhCioZl8HUB9MTikEBZCCIDt27ezbNkyVFVlxIgRJCcnl3n+66+/Zs2aNQCYzWYmT55M+/btvR9oJUp7hN1TqLl8G4wQQtd00yNscsgYYSGEUFWVpUuX8uCDD/Lcc8+xadMmjhw5UmafFi1a8Oijj7Jw4UL+9Kc/8frrr/so2opJj7AQwlt0Uwgbi2SMsBBCpKWlER0dTcuWLTGZTAwZMoQtW7aU2adLly6EhYUB0KlTJzIzM30RaqVkjLAQwlt00cqUlIBZdfcIq9IjLIRowrKysrBarZ7HVquVrKysSvf//PPP6devnzdCq7HSHmGZS1gI0dB0MUbYblcIpQCQHmEhRNOmVTD5rqJUXFD++uuvbNy4kccff7zC51NSUkhJSQFg/vz52Gy2Kq9tMpmq3ac2NM2CzRZab+c7X/WdX2Ok9xwlP/9X3znqphAOQcYICyGE1WotM9QhMzOTyMjIcvsdPHiQ1157jdmzZ2OxWCo8V2JiIomJiZ7HGRkZVV7bZrNVu09NFBcDxHDiRCEZGfnnfb76Ul/5NWZ6z1Hy8391zTEmJqbC7boYGiE9wkII4RYXF8fx48dJT0/H6XSSmprKgAEDyuyTkZHBwoULueuuuyr94+BLgYFgNmtnZo0QQoiGo4seYYfDXQirBqO7BRVCiCbKaDQyadIk5s2bh6qqJCQkEBsby/r16wFISkriv//9L/n5+SxZssRzzPz5830ZdjlhYarMGiGEaHC6KIRLe4SdQSFQyVg4IYRoKuLj44mPjy+zLSkpyfP1HXfcwR133OHtsGolLEwjP1/acyFEw9LF+06lY4RdQTI+WAgh9CA8XCU3Vxd/ooQQjZguWpnSHmE1WMYHCyGEHkiPsBDCG6QQFkII0ehYLKrcLCeEaHC6aGU8s0bIjBFCCKELFosmN8sJIRqcbgrhEAohRMYICyGEHlgsqiyxLIRocLpoZTw9wmFSCAshhB6Ehbl7hCtYKE8IIeqNrgphQ5gMjRBCCD0ID9dwuRTsdhkeIYRoOLoqhAmVHmEhhNCDsDAVQMYJCyEalG4K4RAKZXllIYTQCYvFPSZCCmEhREPSRSFcusSyFiw9wkIIoQcWS2mPsC7+TAkhGildtDAlBSUE4JQeYSGE0AnpERZCeIMuCmE13w4gPcJCCKETf4wR1sWfKSFEI6WPFqagEEB6hIUQQifCw909wrLMshCiIZlqstP27dtZtmwZqqoyYsQIkpOTy+2zY8cOli9fjsvlwmKx8Nhjj9V3rJUrONMjLIWwEELogvQICyG8odpCWFVVli5dyty5c7FarcyePZsBAwbQpk0bzz4FBQUsWbKEOXPmYLPZyMnJadCgz2WwS4+wEELoSViYjBEWQjS8av/VTktLIzo6mpYtW2IymRgyZAhbtmwps88333zDoEGDsNlsAERERDRMtJUwOGSMsBBC6ElAAAQHq9IjLIRoUNX2CGdlZWG1Wj2PrVYre/bsKbPP8ePHcTqdPProo9jtdi6//HKGDx9e/9FWwuCQHmEhhNAbi0WTMcJCiAZVbSGsVbDQu6KUbZhcLhf79+/noYceori4mLlz59KpUydiYmLK7JeSkkJKSgoA8+fP9/QgVxiYyVTl82cLKHb3CEfExKDV8JjGoDY5+iO95wf6z1Hv+UHTyNFfhYVp5OZKj7AQouFUWwhbrVYyMzM9jzMzM4mMjCy3j8ViwWw2Yzab6datGwcPHixXCCcmJpKYmOh5nJGRUel1bTZblc+fzejIByCrqAhXDY9pDGqToz/Se36g/xz1nh/UPcdz2zdR/8LDVekRFkI0qGr/1Y6Li+P48eOkp6fjdDpJTU1lwIABZfYZMGAAv//+Oy6Xi6KiItLS0mjdunWDBX02TfujR1jGCAshhH6EhWkyRlgI0aCq7RE2Go1MmjSJefPmoaoqCQkJxMbGsn79egCSkpJo06YNffv25b777sNgMHDZZZfRtm3bBg8eoLgYgjUZIyyEEHpjsaicOlWjWT6FEKJOatTCxMfHEx8fX2ZbUlJSmcfjxo1j3Lhx9RdZDRUUGAilAJBCWAgh9MRi0WT6NCFEg/L795yOHjUSSgEuY4B7vh0hhBC6YLGo5Of7/Z8pIUQj5vctzMGDRkIoRDXL+GAhhNAT9xhhBVX1dSRCCL3y+0L40CGTe2hEqAyLEEIIPQkPV9E0hcJCGR4hhGgYfl8IHzxoJDIwHyVUeoSFEEJPZJllIURD8/tC+NAhIzZzvtwoJ4QQOmOxuMdEyBRqQoiG4vfz0hw8aKJZYIHMISyEEGds376dZcuWoaoqI0aMIDk5uczzR48e5ZVXXmH//v3ccMMNPpnxpyYsFukRFkI0LL/+N9vphCNHjISbClClR1gIIVBVlaVLl/Lggw/y3HPPsWnTJo4cOVJmn7CwMP72t79x5ZVX+ijKmikthGXmCCFEQ/Hr1uXYMSMul0KYUiBDI4QQAkhLSyM6OpqWLVtiMpkYMmQIW7ZsKbNPREQEHTt2xGg0+ijKmgkLcw+NyM2VHmEhRMPw60L44EF3Ix6sFsrQCCGEALKysrBarZ7HVquVrKwsH0ZUd+Hh0iMshGhYfj1G+NAhd/iBzkJKpEdYCCHQNK3cNkWpW49qSkoKKSkpAMyfPx+bzVbl/iaTqdp9asN05i+UqoZhs/m+ja/v/Bojveco+fm/em9n6u1MPnDokJGAAA1TUSHF0iMshBBYrVYyMzM9jzMzM4mMjKzTuRITE0lMTPQ8zsjIqHJ/m81W7T614XIBxHDihJ2MjLx6O29d1Xd+jZHec5T8/F9dc4yJialwu1+/33TwoIk2rZ0ohYUyRlgIIYC4uDiOHz9Oeno6TqeT1NRUBgwY4Ouw6sRohNBQVWaNEEI0GL/uET540EjHtoUoB1QZIyyEEIDRaGTSpEnMmzcPVVVJSEggNjaW9evXA5CUlMTp06eZNWsWdrsdRVH43//+x7PPPktII+xQsFg0KYSFEA3GrwvhQ4dMDOvifgtQCwvzcTRCCNE4xMfHEx8fX2ZbUlKS5+tmzZqxePFib4dVJ2FhqiyoIYRoMH7bupw+rXD6tIH4oF8BcHbs6OOIhBBC1DeLRSM/X3qEhRANw28L4cOH3Z3Z3Yp/AaCke3dfhiOEEKIBWCwqubl++6dKCNHI+W3rUjqHcGz2r7iaN0fV+XQhQgjRFIWFSY+wEKLh+G0hXDqHsPXor9IbLIQQOhUeLmOEhRANx29bl4MHjbSIdBCUthunFMJCCKFLFotGTo5CBeuECCHEefPbWSMOHTIyrOVvKL8XS4+w8FuapuFwOFBVtc6rfzWkkydPUlRU5OswGlRVOWqahsFgwGw2N8rvT1PQrVsJdruBXbtMdO3q9HU4Qgid8dtC+OBBE+OtPwJyo5zwXw6Hg4CAAEymxvmraDKZMBqNvg6jQVWXo9PpxOFwECxzlfvEkCHFAGzeHCiFsBCi3vnl0AinE44cMdKbn9ECA3HGxfk6JCHqRFXVRlsECzeTyYSqqr4Oo8mKjXXRpo2T1NQgX4cihNAhvyyEjx0z4nIpxBX8irNTJwgI8HVIQtSJvN3uH+T75FtDhhSzeXMg8v+IEKK++WUhXDp1WvTJX2RYhBDnISsri5EjRzJy5Ej69u1L//79PY+Li4urPPann37ioYceqvYa48aNq69wRRN10UVFZGcb+f13efdECFG//LJVOXTIRHPSCT6dTo4UwkLUWVRUFBs2bABg0aJFhIaGcscdd3iedzorH5PZp08f+vTpU+011q5de/6Biibtj3HCQXTvLuOEhRD1x08LYSP9jdvBJTfKCVHfZsyYQbNmzfj111/p06cPY8eO5ZFHHsHhcGA2m3n22Wfp2LEjqampLF68mBUrVrBo0SKOHj3KoUOHOHr0KJMnT+aWW24BoFOnTuzZs4fU1FSeffZZIiMj2bVrF7179+all15CURQ+++wzHnvsMaKioujVqxcHDx5kxYoVZeI6fPgw06ZNo7CwEIAnn3ySCy+8EIBXXnmF999/H0VRuOyyy3jwwQfZv38/s2bNIjMzE6PRyGuvvUb79u29+lqK+tGmjYu2bZ2kpgZyyy0Fvg5HCKEjflkIHzxo4pKI7ZCFzCEsdOPhh8PZubN+x7t3717C44/n1vq4ffv2sXLlSoKCgsjOzmbVqlWYTCa++uor/u///o833nij3DFpaWm89957FBQUcMkll3DTTTcRcM74/V9//ZXPP/+c6Ohoxo8fz5YtW+jduzcPPPAAq1atom3btkyZMqXCmGw2G++++y5ms5l9+/YxdepUPvnkEz7//HPWrVvHRx99RHBwMNnZ2QDcfffdTJ06lTFjxuBwONBkIlq/NmRIEevWBaOqYPDLQX1CiMbITwthI3cF/IQrOho1KsrX4QihO2PHjvVMKZabm8uMGTPYv38/iqJQUlJS4TEjRowgKCiIoKAgbDYbp06dIiYmpsw+ffv29Wzr0aMHhw8fJiQkhHbt2tG2bVsAkpOTeeutt8qdv6SkhDlz5rBz504MBgP79u0D4Ouvv+b666/3TG8WGRlJfn4+x48fZ8yYMQCYzeZ6eFWEL110UTH//ncoO3ea6NlThkcIIeqHXxbChw6Z6Kr8TEk/6Q0W+lGXntuGEhIS4vn6mWeeYciQISxdupTDhw9zzTXXVHhMUNAf01sZjUZcLle5fQIDA8vsU9UY5HO98cYbNG/enA0bNqCqKhdccAHgXvTi3FkdpPdXfy66yL3oyebNQVIICyHqjd+9wXT6tELBaScxObtkfLAQXpCXl0d0dDQA//nPf+r9/HFxcRw8eJDDhw8Dld9cl5ubS4sWLTAYDLz//vueQnv48OH8+9//xm63A5CdnY3FYqFVq1asW7cOgKKiIs/zwj+1bq3Svr17nLAQQtQXvyuEDx820Y3fMKklUggL4QV33nknTz/9NOPHj6+wl/d8BQcH89RTTzFhwgSSk5Ox2WyEh4eX2+/mm2/mv//9L2PHjmXfvn2eXuuEhASSkpIYM2YMI0eOZPHixQC8+OKLLF26lMTERMaPH096enq9xy68a8iQIr77LogG+DEUQjRRiubD9xCPHTtW6XM2m42MjIxy2z/6yMw3t3/ECm4mfeNGnJ07N2SIDaqyHPVC7/nB+edYWFhYZhhCY2MymWo1fKGuCgoKCA0NRdM0HnzwQTp06MBtt93W4NeFmuVY0ffp3PHPTUFVbTY0/O/8qlXB3H13JJ9+mu6T4RHSpvk/yc//1TXHytpsv+sRPnTIRB9+Qg0MwnlmjKAQwr+9/fbbjBw5koSEBPLy8pg4caKvQxKNUOk44U2bZLllIUT98Lub5Q4eNJJo+gln1y5g8rvwhRAVuO2227zWAyz8V6tWKh06ONm8OYjbb5f5hIUQ58//eoQPGujNzzI+WAghmiD3OOFAGScshKgXflcIF+7LIMp5ShbSEEKIJmjIkGJycw3s2FG/i88IIZomvyqEnU5ocfxXAEq6dfNxNEIIIbytdJywTKMmhKgPflUIHztmpKf6M4AMjRBCiCaoZUuVuLgSUlPlhjkhxPnzq0L44EEjvfmZQmtrtGbNfB2OEH7vmmuu4Ysvviiz7Y033mD27NlVHvPTTz8BMHHiRHJycsrts2jRIs98vpVZt24du3fv9jx+5pln+Oqrr2oRvWiqhgwp5rvvAvHCzH5CCJ3zq0K4dOq0om7SGyxEfRg/fjxr1qwps23NmjUkJyfX6Pg333yTiIiIOl373EL4/vvvZ9iwYXU6l2haLrqoiPx8A7/+KuOEhRDnx68K4WP7SujK7xj6yfhgIerDFVdcQUpKCkVF7nGXhw8f5uTJkwwcOJBZs2aRlJREQkICCxcurPD4QYMGkZWVBcALL7zAJZdcwvXXX8/evXs9+7z99ttcfvnlJCYmcuutt2K329myZQsbNmzgySefZOTIkRw4cIAZM2bw0UcfAfD111+TlJTEiBEjuOeeezzxDRo0iIULFzJq1ChGjBhBWlpauZgOHz7MVVddxahRoxg1ahRbtmzxPPfKK68wYsQIEhMTeeqppwDYv38/119/PYmJiYwaNYoDBw6c/wsrGtSQIcUAvPNOCKdPKz6ORgjhz2o0Ee/27dtZtmwZqqoyYsSIcr1FO3bsYMGCBbRo0QJw/7G65ppr6j1YbcceTLhwdZdCWOhP+MMPE7BzZ72es6R7d3Iff7zS56Oioujbty9ffPEFo0aNYs2aNYwbNw5FUXjggQdo3rw5RUVFXH/99ezcuZPulYzN//nnn1m7di3r16/H6XQyevRoevfuDcCYMWOYMGECAP/3f//Hu+++y6RJkxg5ciSJiYmMHTu2zLkcDgczZ85k5cqVxMXFMW3aNFasWMGtt97qifnTTz9l+fLlLF68uFyRbrPZePfddzGbzezbt4+pU6fyySef8Pnnn7Nu3To++ugjgoODyc7OBtxLSE+dOpUxY8bgcDjw4WKb9aa6NlvTNJYtW8aPP/5IUFAQU6ZM4QI/WqCoeXOVpCQ7b78dynvvhXDZZQ6Sk+0kJjoIDvZ1dEIIf1JtIayqKkuXLmXu3LlYrVZmz57NgAEDaNOmTZn9unXrxqxZsxosUIALA93jEuVGOSHqT3JyMmvWrPEUws8++ywAH374Ie+88w5Op5OTJ0+yZ8+eSgvh7777jtGjRxN8pgoZOXKk57ldu3axYMECcnNzKSgoYPjw4VXGs3fvXtq2bUtcXBwA1157Lf/61788hfCYMWMA6N27N5988km540tKSpgzZw47d+7EYDCwb98+wN3LfP3113tijIyMJD8/nxMnTnjOaTaba/aiNWI1abN//PFHTpw4wYsvvsiePXtYsmSJp4fcX/zzn9n8/HM+q1cHs3ZtMOvWBRMaqpKU5KBDBxdWqwubTaV5cxWr1UVkpIbZ7P4wGn0dvRCisai2EE5LSyM6OpqWLVsCMGTIELZs2VKuEPaG8R22oZrNuDp08Pq1hWhoVfXcNqTRo0fz2GOP8csvv+BwOOjVqxeHDh3itdde49NPPyUsLIwZM2bgcDiqPI+iVPwW9cyZM1m6dCk9evRg5cqVbN68ucrzVNcjGxTkni3AaDTiqmBVhTfeeIPmzZuzYcMGVFX19HRqmlYuRj30/p6rJm32Dz/8wLBhw1AUhc6dO1NQUEB2djaRkZG+CrvWFAX69CmhT58SHnool82bA1mzJpiUFDMffGBA0yofMhEY+EdRHBioERDg3mYylX52f+3+cBfOJpNGcLAJpzMSo1HDYACjEYxG9/OK4n5sMLifMxjc29xfu7dB2e3uz5onn8o/NEp/dEu3Vf31H/uXPnfu54q2AVgsBvLzQzznOfcc534P6vp1Vduq3l7z39mKzhEebiAvr/w/vJVdr6bnra/9z3dfi0WpML/aqm2OtTv3+bW7cXEKZ/pJ6kW1hXBWVhZWq9Xz2Gq1smfPnnL77d69m/vvv5/IyEgmTpxIbGxsuX1SUlJISUkBYP78+dhstsoDM5nKPW9KS4NevbCdaeD9XUU56one84Pzz/HkyZOYfLxUeEREBBdffDH33nsvV199NSaTCbvdTkhICOHh4WRkZLBx40aGDh2KyWRCURSMRmOZry+++GKmTZvG9OnTcblcpKSkcNNNN2EymSgoKCAmJgZN0/jggw9o1aoVJpMJi8WC3W735G8wGDAajXTt2pUjR45w+PBhOnTowOrVqxkyZEi5axuNRhRFKff65efnExMTQ2BgIO+++y4ulwuTycRll13GokWLuOaaawgJCfEUfq1atWL9+vVcfvnlFBUV4XK5CAkJKXPOoKAgv/lZrkmbnZWVVSYfq9VKVlZWuUK4Nm02+PZ3PjnZ/QEunE4XmZmQnq6Qng6nTilkZYHdDg4HFBYq2O3ux8XFCiUlUFxsoLiYM1+Dy+Weu97hcH92OsHlUnA6zbhc7udVtfzn0q9dLtA090fp9tIP9/bGPLa5ma8DaGBRvg6ggek7v1GjNNaurb92ptq/wBX1mJzbq9KhQwdeeeUVzGYz27Zt45lnnuHFF18sd1xiYiKJiYmexxkZGZVe12azlXvesHAhhtOncVZxnD+pKEc90Xt+cP45FhUVYWwE79OOGzeOyZMn88orr+B0OunSpQs9evRg2LBhxMbGcuGFF+JyuXA6nWiaVu7r7t27c+WVV3LZZZfRpk0bBg4ciKqqOJ1O7rvvPsaMGUObNm3o2rUr+fn5OJ1Oxo0bx/33388bb7zB66+/jqqqnqJ10aJF3HLLLbhcLvr06cOECRPKXdvlcqFpGs5z5tCaOHEit912G2vWrOHiiy8mJCQEp9PJsGHD+Pnnn0lKSiIgIIDLLruM2bNn8/LLL3PvvfeyYMECTCYTr732Gu3atStzzqKionLf55iYmAb/vtRFTdrsmuwDtWuzoXH9zhuN0KqV+6O+1Hd+ZxfKpV+f/QFKJdsr//rsY0qfO/dzVc9FRUWduQH2j5+Hs39czj2mLl9Xta2q7WfHVNdzNGsW6bk/oPrr1Sa289+/PvaNjCyfX2NSH/8AxsZG1On3sLI2W9GqeW9w9+7dvPfee8yZMweA1atXA3DVVVdVeszUqVN5+umnCQ8PrzKoY8eOVfpcY2pQG4rec9R7fnD+ORYWFpbrfWxMTCZTuUJTb2qSY0Xfp8ZaCNekzX799dfp3r07Q4cOBWD69Ok8+uij1Q6NqKrNBv3/zus9P9B/jpKf/6trjpW12dVOnxYXF8fx48dJT0/H6XSSmprKgAEDyuxz+vRpTw9DWloaqqpisVhqHaQQQojzU5M2e8CAAXz11Vdomsbu3bsJCQnxq/HBQghRX6odGmE0Gpk0aRLz5s1DVVUSEhKIjY1l/fr1ACQlJfHtt9+yfv16jEYjgYGBzJgxo9IbZ4QQQjScmrTZ/fr1Y9u2bUybNo3AwECmTJni46iFEMI3qh0a0ZBkaIS+c9R7fiBDI/RAb0MjGpIMjdB3fqD/HCU//+f1oRFCiIajx+m79Ei+T0IIoU9SCAvhQwaDQfc9rv7O6XRiMEhTKYQQeuTbCUyFaOLMZjMOh4OioqJGOa4+KCiIoqIiX4fRoKrKUdM0DAaDLlacE0IIUZ4UwkL4kKIoniV/GyMZbyaEEELP5P0+IYQQQgjRJEkhLIQQQgghmiQphIUQQgghRJPk03mEhRBCCCGE8JVG2yM8a9YsX4fQ4PSeo97zA/3nqPf8oGnk6C16fy31nh/oP0fJz//Vd46NthAWQgghhBCiIUkhLIQQQgghmqRGWwgnJib6OoQGp/cc9Z4f6D9HvecHTSNHb9H7a6n3/ED/OUp+/q++c5Sb5YQQQgghRJPUaHuEhRBCCCGEaEiNconl7du3s2zZMlRVZcSIESQnJ/s6pPP2yiuvsG3bNiIiIli0aBEA+fn5PPfcc5w6dYrmzZszc+ZMwsLCfBxp3WRkZPDyyy9z+vRpFEUhMTGRyy+/XDc5FhcX88gjj+B0OnG5XAwePJjrrrtON/mVUlWVWbNmERUVxaxZs3SX39SpUzGbzRgMBoxGI/Pnz9ddjr4gbbb/kTbbv/M7m57bba+02Voj43K5tLvuuks7ceKEVlJSot13333a4cOHfR3WeduxY4e2d+9e7Z577vFse/PNN7XVq1drmqZpq1ev1t58800fRXf+srKytL1792qapmmFhYXatGnTtMOHD+smR1VVNbvdrmmappWUlGizZ8/Wdu3apZv8Sn344Yfa888/rz399NOapunrZ1TTNG3KlClaTk5OmW16y9HbpM32T9Jm+3d+Z9Nzu+2NNrvRDY1IS0sjOjqali1bYjKZGDJkCFu2bPF1WOete/fu5f5j2bJlC8OHDwdg+PDhfp1nZGQkF1xwAQDBwcG0bt2arKws3eSoKApmsxkAl8uFy+VCURTd5AeQmZnJtm3bGDFihGebnvKrTFPIsSFJm+2fpM327/xKNcV2u77za3RDI7KysrBarZ7HVquVPXv2+DCihpOTk0NkZCTgbpRyc3N9HFH9SE9PZ//+/XTs2FFXOaqqygMPPMCJEycYNWoUnTp10lV+y5cv58Ybb8Rut3u26Sm/UvPmzQNg5MiRJCYm6jJHb5I22/9Jm+2/mkK73dBtdqMrhLUKJrFQFMUHkYi6cDgcLFq0iL/+9a+EhIT4Opx6ZTAYeOaZZygoKGDhwoUcOnTI1yHVm61btxIREcEFF1zAjh07fB1Og3niiSeIiooiJyeHJ598kpiYGF+H5PekzfZv0mb7r6bQbnujzW50hbDVaiUzM9PzODMz01P5601ERATZ2dlERkaSnZ1NeHi4r0M6L06nk0WLFnHJJZcwaNAgQH85AoSGhtK9e3e2b9+um/x27drFDz/8wI8//khxcTF2u50XX3xRN/mVioqKAtw/lxdeeCFpaWm6y9HbpM32X9Jm+3d+TaHd9kab3ejGCMfFxXH8+HHS09NxOp2kpqYyYMAAX4fVIAYMGMCXX34JwJdffsmFF17o44jqTtM0Fi9eTOvWrRk7dqxnu15yzM3NpaCgAHDfjfzLL7/QunVr3eT3l7/8hcWLF/Pyyy8zY8YMevbsybRp03STH7h7vkrfPnQ4HPz888+0bdtWVzn6grTZ/knabP/OD/TfbnurzW6UC2ps27aNf/3rX6iqSkJCAldffbWvQzpvzz//PDt37iQvL4+IiAiuu+46LrzwQp577jkyMjKw2Wzcc889fjvFye+//87DDz9M27ZtPW+L/vnPf6ZTp066yPHgwYO8/PLLqKqKpmlcdNFFXHPNNeTl5ekiv7Pt2LGDDz/8kFmzZukqv5MnT7Jw4ULAffPM0KFDufrqq3WVo69Im+1/pM327/zOpcd221ttdqMshIUQQgghhGhojW5ohBBCCCGEEN4ghbAQQgghhGiSpBAWQgghhBBNkhTCQgghhBCiSZJCWAghhBBCNElSCAshhBBCiCZJCmEhhBBCCNEkSSEshBBCCCGapP8Hu/6aUBhQ2VIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clear_session()\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=50,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=16)\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.43114984035492 84.50000286102295 47.466060519218445 53.84615659713745 43.02884638309479\n"
     ]
    }
   ],
   "source": [
    "print(loss*100, accuracy*100, f1_score*100, precision*100, recall*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 73ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       200\n",
      "           1       0.00      0.00      0.00       200\n",
      "\n",
      "    accuracy                           0.50       400\n",
      "   macro avg       0.25      0.50      0.33       400\n",
      "weighted avg       0.25      0.50      0.33       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cdwor\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=64, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
